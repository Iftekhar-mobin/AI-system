{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neologdn\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_regex(text, remove_mention=True, remove_url=True):\n",
    "    text = text.lower()\n",
    "    replaced_text = re.sub(r'[【】]', ' ', text)  # 【】の除去\n",
    "    replaced_text = re.sub(r'[・_!！？?☛]', '', replaced_text)  # ・ の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)  # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)  # ［］の除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'[⑤⑥②①③④⑦⑧⑨⑩]', '', replaced_text)\n",
    "    replaced_text = re.sub(r'\\d+', '', replaced_text)  # 数字の除去\n",
    "    replaced_text = re.sub(r'[/。,、.=]', ' ', replaced_text)  # others\n",
    "    replaced_text = re.sub(r'[\u001e",
    "●■]', '', replaced_text)\n",
    "    if remove_mention:\n",
    "        replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    if remove_url:\n",
    "        replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This Web site uses JavaScript. Please let your browser settings enable JavaScript. Mobile Search Close Please choose the service you want to know Previous Next iPhone SE iPhone 11 iPhone 11 Pro iPad Pro Google Pixel 4a Getting a handset in Japan? Visit a SoftBank shop! We will be happy to help you. For new contr acts (switchover), upgrades, and various applications, please make sure the following information. Find a shop where you can speak English We have shops with full-time English speaking staff. What you need to prepare Information on required items when purchasing a handset or changing subscription content, and more. See our multilingua l catalogs We have（digital）catalogs available in English, Chinese, Spanish, Korean, Vietnamese, and Portuguese. Need help? If you have any questions, please contact o ur customer support. We provide support in English. Products Special English-speaking staff are available at these locations Account and Services Social Media Use socia l media to follow us for up-to-date news and details of our latest activities (Japanese only) Font size Registration number(Telecommunications carrier):No.72 Top of pag e.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 'メールサービスがこない'\n",
    "test = 'ポイント　利用できない'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ポイント', '利用', 'できる']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, new_words = _filter_by_pos(replace_with_regex(neologdn.normalize(test)), NOUN_POS)\n",
    "words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ifte/resource/docomo_dic/data/merged_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "for row, col in df.iterrows():\n",
    "    # words, new_words = _filter_by_pos(replace_with_regex(neologdn.normalize(str(col['text']))), NOUN_POS)\n",
    "    items = replace_with_regex(neologdn.normalize(str(col['text'])))\n",
    "    for match in re.finditer(r'd[ァ-ンー]+', items):\n",
    "        collector.append(items[match.start(): match.end()])\n",
    "    # print(replace_with_regex(neologdn.normalize(str(col['text']))))\n",
    "    # print(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(collector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in list(set(collector)):\n",
    "    print(items,\",,,2000,名詞,固有名詞,一般,*,*,*,\",items ,\",*,*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = replace_with_regex(neologdn.normalize(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this web site uses javascript  please let your browser settings enable javascript  mobile search close please choose the service you want to know previous next iphone se iphone  iphone  pro ipad pro google pixel a getting a handset in japan visit a softbank shop we will be happy to help you  for new contr acts  switchover   upgrades  and various applications  please make sure the following information  find a shop where you can speak english we have shops with full-time english speaking staff  what you need to prepare information on required items when purchasing a handset or changing subscription content  and more  see our multilingua l catalogs we have digital catalogs available in english  chinese  spanish  korean  vietnamese  and portuguese  need help if you have any questions  please contact o ur customer support  we provide support in english  products special english-speaking staff are available at these locations account and services social media use socia l media to follow us for up-to-date news and details of our latest activities  japanese only  font size registration number telecommunications carrier :no  top of pag e '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab \n",
    "tagger = MeCab.Tagger(\"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Air\\t名詞,固有名詞,一般,*,*,*,Air,エア,エア\\nEOS\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.parse('Air')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ポイント\\t名詞,一般,*,*,*,*,ポイント,ポイント,ポイント\\nが\\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\\n利用\\t名詞,サ変接続,*,*,*,*,利用,リヨウ,リヨー\\nでき\\t動詞,自立,*,*,一段,連用形,できる,デキ,デキ\\nませ\\t助動詞,*,*,*,特殊・マス,未然形,ます,マセ,マセ\\nん\\t助動詞,*,*,*,不変化型,基本形,ん,ン,ン\\n。\\t記号,句点,*,*,*,*,。,。,。\\nEOS\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.parse('ポイントが利用できません。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ポイント\\t名詞,一般,*,*,*,*,ポイント,ポイント,ポイント\\nが\\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\\n利用\\t名詞,サ変接続,*,*,*,*,利用,リヨウ,リヨー\\nでき\\t動詞,自立,*,*,一段,連用形,できる,デキ,デキ\\nませ\\t助動詞,*,*,*,特殊・マス,未然形,ます,マセ,マセ\\nん\\t助動詞,*,*,*,不変化型,基本形,ん,ン,ン\\n。\\t記号,句点,*,*,*,*,。,。,。\\nEOS\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.parse('ポイントが利用できません。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "NOUN_POS = ('名詞', '動詞', '形容詞', '接頭詞',)\n",
    "STOP_POS = ('記号', 'フィラー',)\n",
    "NEW_WORD = '固有名詞'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, new_words = _filter_by_pos(text, NOUN_POS)\n",
    "# words = correct_words(words, checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_new_word(token):\n",
    "    if token.reading == '' and token.phonetic == '' and token.pos_detail1 == NEW_WORD and len(token.surface) > 1:\n",
    "        return token.surface\n",
    "    return None\n",
    "\n",
    "def _filter_by_pos(sent, pos):\n",
    "    base_forms = []\n",
    "    new_words = []\n",
    "    for token in _tokenize(sent):\n",
    "        if token.pos in pos:\n",
    "            if token.base_form != '*':\n",
    "                base_forms.append(token.base_form)\n",
    "            else:\n",
    "                base_forms.append(token.surface)\n",
    "            new_word = _get_new_word(token)\n",
    "            if new_word is not None:\n",
    "                new_words.append(new_word)\n",
    "    return base_forms, new_words\n",
    "\n",
    "def _tokenize(text):\n",
    "    chunks = tagger.parse(text.rstrip()).splitlines()[:-1]  # Skip EOS\n",
    "    token = namedtuple('Token', 'surface, pos, pos_detail1, pos_detail2, pos_detail3, '\n",
    "                                'infl_type, infl_form, base_form, reading, phonetic')\n",
    "    for chunk in chunks:\n",
    "        if chunk == '':\n",
    "            continue\n",
    "        try:\n",
    "            surface, feature = chunk.split('\\t')\n",
    "            feature = feature.split(',')\n",
    "            if len(feature) <= 7:  # 読みがない\n",
    "                feature.append('')\n",
    "            if len(feature) <= 8:  # 発音がない\n",
    "                feature.append('')\n",
    "            yield token(surface, *feature)\n",
    "        except:\n",
    "            print('Exception occurred')\n",
    "\n",
    "\n",
    "def collect_english_words(raw_texts):\n",
    "    collector = []\n",
    "    for items in ' '.join(map(str, raw_texts)).lower().split():\n",
    "        if bool(re.compile('.*[a-z].*').match(items)):\n",
    "            clean = re.sub(r'[^a-z]', '', items)\n",
    "            if len(clean) > 1:\n",
    "                collector.append(clean)\n",
    "    # print(collector)\n",
    "    with open(\"correction_vocab.txt\", 'w') as out:\n",
    "        out.writelines(\"%s\\n\" % vocab for vocab in list(set([x for x in collector if len(x) > 1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_english_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "checker = enchant.DictWithPWL(\"en\",\"correction_vocab.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['t', 'HIS', 'web', 'SIT', 'e', 'u', 'SES', 'p', 'l', 'ease', 'Ll', 'e', 't', 'r', 's', 'Ett', 'ING', 's', 'SEA', 'r', 'c', 'h', 'p', 'l', 'ease', 'c', 'h', 'o', 'OSE', 'the', 'SE', 'r', 'vice', 'you', 'w', 'ant', 't', 'o', 'k', 'NOW', 'p', 'r', 'evio', 'us', 'p', 'r', 'o', 'a', 'GET', 't', 'ING', 'a', 'h', 'ANDS', 'e', 't', 't', 'n', 'vis', 't', 't', 'a', 'SHO', 'p', 'w', 'e', 'b', 'e', 't', 'o', 'h', 'ELP', 'n', 'e', 'w', 'c', 'o', 'NTR', 'a', 'CTS', 'pl', 'easel', 'sear', 'ch', 'p', 'l', 'ease', 'c', 'ho', 'ose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words(words, checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0\n",
    "while p < 3: \n",
    "    words = correct_words(words, checker)\n",
    "    if not [x for x in words if len(x) < 2]:\n",
    "        break\n",
    "    p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_words(words, checker):\n",
    "    q = 2\n",
    "    words = [x.lower() for x in words]\n",
    "    correction = defaultdict(list)\n",
    "    i = 0\n",
    "    for items in words:\n",
    "        flag = 1\n",
    "        if len(items) < 3 and bool(re.compile('[a-z]').match(items)):\n",
    "            # print(items, '=', i)\n",
    "            try:\n",
    "                k = 0\n",
    "                while k < q:\n",
    "                    check_word, collect_index = collect_word_index(words, i, q, k)\n",
    "                    if checker.check(check_word):\n",
    "                        correction[check_word].append(collect_index)\n",
    "                        flag = 0\n",
    "                        break\n",
    "                    k += 1\n",
    "                if flag:\n",
    "                    k = 0\n",
    "                    while k < q+1:\n",
    "                        check_word, collect_index = collect_word_index(words, i, q+1, k)\n",
    "                        if checker.check(check_word):\n",
    "                            correction[check_word].append(collect_index)\n",
    "                            flag = 0\n",
    "                            break\n",
    "                        k += 1\n",
    "                if flag:\n",
    "                    k = 0\n",
    "                    while k < q+2:\n",
    "                        check_word, collect_index = collect_word_index(words, i, q+2, k)\n",
    "                        if checker.check(check_word):\n",
    "                            correction[check_word].append(collect_index)\n",
    "                            break\n",
    "                        k += 1\n",
    "\n",
    "            except (IndexError, ValueError) as e:\n",
    "                pass\n",
    "        i += 1\n",
    "    return get_corrected_words(correction, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_word_index(words, i, j, k):\n",
    "    check_word = ''\n",
    "    collect_index = []\n",
    "    while j > 0:\n",
    "        index = i - j + k\n",
    "        if not (index < 0 or index > len(words)): \n",
    "            check_word += str(words[i - j + k])\n",
    "            collect_index.append(i - j + k)\n",
    "        j -= 1\n",
    "    return check_word, collect_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_words(words, checker):\n",
    "    words = [x.lower() for x in words]\n",
    "    correction = defaultdict(list)\n",
    "    i = 0\n",
    "    for items in words:\n",
    "        flag = 1\n",
    "        if len(items) < 3 and bool(re.compile('[a-z]').match(items)):\n",
    "            # print(items, '=', i)\n",
    "            try:\n",
    "                k = 0\n",
    "                while k < 4:\n",
    "                    check_word, collect_index = collect_word_index(words, i, 4, k)\n",
    "                    if checker.check(check_word):\n",
    "                        correction[check_word].append(collect_index)\n",
    "                        flag = 0\n",
    "                        break\n",
    "                    k += 1\n",
    "                if flag:\n",
    "                    k = 0\n",
    "                    while k < 3:\n",
    "                        check_word, collect_index = collect_word_index(words, i, 3, k)\n",
    "                        if checker.check(check_word):\n",
    "                            correction[check_word].append(collect_index)\n",
    "                            flag = 0\n",
    "                            break\n",
    "                        k += 1\n",
    "                if flag:\n",
    "                    k = 0\n",
    "                    while k < 2:\n",
    "                        check_word, collect_index = collect_word_index(words, i, 2, k)\n",
    "                        if checker.check(check_word):\n",
    "                            correction[check_word].append(collect_index)\n",
    "                            break\n",
    "                        k += 1\n",
    "\n",
    "            except IndexError:\n",
    "                pass\n",
    "        i += 1\n",
    "    words = get_corrected_words(correction, words)\n",
    "    correction = defaultdict(list)\n",
    "    i = 0\n",
    "    for items in words:\n",
    "        flag = 1\n",
    "        if len(items) < 3 and bool(re.compile('[a-z]').match(items)):\n",
    "            # print(items, '=', i)\n",
    "            try:\n",
    "                k = 0\n",
    "                while k < 3:\n",
    "                    check_word, collect_index = collect_word_index(words, i, 3, k)\n",
    "                    if checker.check(check_word):\n",
    "                        correction[check_word].append(collect_index)\n",
    "                        flag = 0\n",
    "                        break\n",
    "                    k += 1\n",
    "                if flag:\n",
    "                    k = 0\n",
    "                    while k < 2:\n",
    "                        check_word, collect_index = collect_word_index(words, i, 2, k)\n",
    "                        if checker.check(check_word):\n",
    "                            correction[check_word].append(collect_index)\n",
    "                            break\n",
    "                        k += 1\n",
    "\n",
    "            except IndexError:\n",
    "                pass\n",
    "        i += 1\n",
    "    return get_corrected_words(correction, words)\n",
    "\n",
    "\n",
    "def get_corrected_words(correction, words):\n",
    "    for key, val in correction.items():\n",
    "        flag = 1\n",
    "        for items in val[0]:\n",
    "            if flag:\n",
    "                words[items] = key\n",
    "                flag = 0\n",
    "            else:\n",
    "                words[items] = ''\n",
    "\n",
    "    return [x for x in words if x is not '']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
