{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "# myconf = SparkConf().setAll([\n",
    "#     (\"spark.driver.memory\", \"32G\"),\n",
    "#     (\"spark.driver.cores\", \"10\"),\n",
    "#     (\"spark.executor.cores\", \"5\"),\n",
    "#     (\"spark.executor.memory\", \"15G\"),\n",
    "#     (\"spark.rpc.message.maxSize\",\"800\"),\n",
    "#     (\"spark.default.parallelism\",\"2000\"),\n",
    "# ])\n",
    "\n",
    "# conf = pyspark.SparkConf()\n",
    "# conf.setMaster('spark://head_node:56887')\n",
    "# conf.set('spark.authenticate', True)\n",
    "# conf.set('spark.authenticate.secret', 'secret-key')\n",
    "# sc = SparkContext(conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "def init_SparkContext():\n",
    "    if sc:\n",
    "        SparkContext.stop(sc)\n",
    "    SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "    SparkContext.setSystemProperty(\"spark.driver.memory\", \"3G\")\n",
    "    sc_init = SparkContext(master='spark://192.168.20.175:7077',\n",
    "                              appName='Word2vec PySpark Trainer')#\\\n",
    "                            #.setSystemProperty(\"spark.dynamicAllocation.enabled\", \"True\")\n",
    "    return sc_init \n",
    "sc = init_SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "rdd = data_splitter(True)\n",
    "model = Word2Vec(sentences=[x for x in rdd.toLocalIterator()], size=100, window=5, min_count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_dataframe_session():\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark_session = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark dataframe access\") \\\n",
    "        .getOrCreate()\n",
    "    return spark_session\n",
    "\n",
    "def data_splitter(split=True):    \n",
    "    if split:\n",
    "        dataset = sc.textFile(\"hdfs://localhost:9000/dataset/converted.csv\")\\\n",
    "                    .map(lambda row: row.split(\" \"))\n",
    "    else:\n",
    "        dataset = sc.textFile(\"hdfs://localhost:9000/dataset/converted.csv\")\n",
    "    #print(dataset.first())\n",
    "    return dataset\n",
    "\n",
    "def word2vec_model(dataset): \n",
    "    from pyspark.mllib.feature import Word2Vec\n",
    "    k = 100         # vector dimensionality\n",
    "    model_structure = Word2Vec() \\\n",
    "        .setVectorSize(k) \\\n",
    "        .setNumIterations(10) \\\n",
    "        .setWindowSize(5)\n",
    "    model_structure.fit(dataset).save()\n",
    "    \n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2Vec.fit(documentDF)\n",
    "\n",
    "result = model.transform(documentDF)\n",
    "for row in result.collect():\n",
    "    text, vector = row\n",
    "    print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.getVectors()\n",
    "\n",
    "synonyms = m.findSynonyms('1', 5)\n",
    "synonyms\n",
    "\n",
    "m.save(\"/home/iftekhar/AI-system/2VECs_models/word2vec/w2v_pyspark_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カスタマイザー タイトル 設定 カスタマイザー サブタイトル 設定 MobiControl 設定 順序 MobiControl\n"
     ]
    }
   ],
   "source": [
    "# To wrok with a dataframe\n",
    "dataset = data_splitter(False)\n",
    "dataset_preDF = dataset.map(lambda row: [row])\n",
    "spark = access_dataframe_session()\n",
    "documentDF = spark.createDataFrame(dataset_preDF)\n",
    "documentDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvv_list = documentDF.select('_1').collect()\n",
    "mvv = documentDF.select(\"_1\").rdd.flatMap(lambda x: x).collect()\n",
    "mvv[0]\n",
    "word2vec_model(documentDF.select(\"_1\").rdd.flatMap(lambda x: x).collect())\n",
    "#result = model.transform(documentDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
