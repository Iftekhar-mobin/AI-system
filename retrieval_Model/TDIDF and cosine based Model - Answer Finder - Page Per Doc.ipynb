{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import random\n",
    "import io\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import MeCab \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "#p = Path(\"/home/ifte/amiebot_project/amie-HelpBot/mobicontrol_data/corpus_mobicontrol.csv\")\n",
    "df = pd.read_csv(\"/home/ifte/amiebot_project/amie-HelpBot/mobicontrol_data/Train_Test_Data/japanese/corpus_ver14.csv\", \n",
    "                 header=0, usecols=[\"page\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ja = []\n",
    "STOPWORD_FILE = Path(\"/home/ifte/amiebot_project/amie-HelpBot/amie_helpbot/\" + '/assets/learning/stopword_ja.txt')\n",
    "with open(STOPWORD_FILE, encoding='utf-8') as fr:\n",
    "    stop_w = fr.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = ['ます', '端末', 'する', '設定', '表示', 'mobicontrol', '選択', '入力', 'アプリ', 'ユーザ', '構成', 'でき', \n",
    "           '画面', '接続', 'ルール', 'ない', 'インストール', 'です', '指定', '管理', 'ad', 'ください', 'この', 'クリック', \n",
    "           '参照', 'ボタン', 'あり', 'チェック', 'コンソール', 'または', '証明', 'id', '項目', 'なり', 'アクセス',\n",
    "           'データ', '対象', '適用', 'いる', 'pc', 'その']\n",
    "stop_words_ja = stop_w + newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = re.sub(r'[【】]', ' ', text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[・_]', '', replaced_text)       # ・ の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'\\d+', '', replaced_text) # 数字の除去\n",
    "    replaced_text = re.sub(r'[-/。,、.=]', ' ', replaced_text)\n",
    "    \n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_words_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"page\"]]\n",
    "X = df[\"text\"].apply(lambda x: mecab.parse(x).strip(\"\\n\"))\n",
    "df['parsed'] = X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.page.unique()\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in list(classes):\n",
    "    arr_index = df[df.page == i].parsed.values\n",
    "    print(arr_index)\n",
    "    #data = ''.join(list(arr_index))\n",
    "    break\n",
    "    #all_data = clean_text(data)\n",
    "    #print(all_data)\n",
    "    #break\n",
    "    \n",
    "    #arr_words = np.array(all_data.split())\n",
    "    #print(arr_words) \n",
    "    \n",
    "    #num = arr_words.shape[0]//c_size\n",
    "    #full = c_size * num\n",
    "    #rest = arr_words.shape[0] - full\n",
    "    \n",
    "    #pad = np.zeros([c_size-rest], dtype=int)\n",
    "    #sc = np.concatenate((arr_words,pad))\n",
    "    #features = sc.reshape(num+1, c_size)\n",
    "    \n",
    "    df_v = pd.DataFrame(all_data,columns=['data'])\n",
    "    df_v[\"cls\"] = i\n",
    "    \n",
    "    #result = pd.concat([result, df_v]) \n",
    "    \n",
    "    \n",
    "#print(result)\n",
    "#result.to_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ''.join(list(arr_index))\n",
    "df_v = pd.DataFrame(columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v.loc[0] = [k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>カスタマイザー から この タイトル を 設定 でき ます 。 カスタマイザー から この ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  カスタマイザー から この タイトル を 設定 でき ます 。 カスタマイザー から この ..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cols = result.iloc[:,:-1]\n",
    "tog = Data_cols.apply(lambda x: ' '.join(x), axis=1)\n",
    "#tog.to_csv(\"tog.csv\")\n",
    "sent = list(tog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent)\n",
    "stop_words_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words_ja, max_df=0.95)\n",
    "vectors = vectorizer.fit_transform(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf score \n",
    "#idf = vectorizer.idf_\n",
    "# visulalize idf score\n",
    "#print(dict(zip(vectorizer.get_feature_names(), idf)))\n",
    "\n",
    "weights = np.asarray(vectors.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TermsWeight = weights_df.sort_values(by='weight', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TermsWeight.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read a question from the user\n",
    "question = [input('Please enter a question: \\n')]\n",
    "question = vectorizer.transform(question)\n",
    "\n",
    "# Rank all the questions using cosine similarity to the input question\n",
    "rank = cosine_similarity(question, vectorizer.transform(sent))\n",
    "\n",
    "# Grab the top 5\n",
    "top = np.argsort(rank, axis=-1).T[-10:]\n",
    "#print(top)\n",
    "\n",
    "for item in range(len(top)):\n",
    "    idx = top[item,0]\n",
    "    \n",
    "    # if the dataset file structure \"Quesition | Answer\" then use following line  \n",
    "    #print(data['Answer'].iloc[item].values[0])\n",
    "    print(\"PageID: \",result.iloc[idx,-1],\"idx\",idx,\"=\",tog.values[idx])\n",
    "    print(\"\\n ########## \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
