{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "KyURNJkaRZZw",
    "outputId": "5f400d7b-4582-4469-9efd-e1742f9ae187"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing, utils \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from string import digits\n",
    "from sklearn.utils import shuffle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "from tensorflow.keras.layers import Dense, Concatenate, GlobalAveragePooling1D, Input, Embedding, LSTM\n",
    "from attention_maker import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wz9NzqICeSOA",
    "outputId": "5fe2c533-8d42-45e1-b38f-f833bd75a01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArlqPQSoSclf"
   },
   "outputs": [],
   "source": [
    "data_file = \"processed_texts.txt\"\n",
    "with open(data_file, encoding='utf-8') as f:\n",
    "    data_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fg3WNnT-0AAX"
   },
   "outputs": [],
   "source": [
    "all_text = \" \".join(data_list)\n",
    "all_text = single_character_remover(all_text)\n",
    "lines = page_text_split(all_text, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPaeOCwy0BqN"
   },
   "outputs": [],
   "source": [
    "sent = np.asarray(lines)\n",
    "\n",
    "if len(sent)%2==0:\n",
    "    sentTwo = sent.reshape(len(sent)//2,2)\n",
    "else:\n",
    "    sent = sent[:-1]\n",
    "    sentTwo = sent.reshape(len(sent)//2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "7ud4OHlW0dQG",
    "outputId": "8d4f1507-9ded-445c-cfaa-b7a3d27d2c3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobicontrol manual mobicontrol manual</td>\n",
       "      <td>サブタイトル 設定 mobicontrol 設定</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>サブタイトル 設定 mobicontrol 設定</td>\n",
       "      <td>mobicontrol 設定 順序 端末</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobicontrol 設定 順序 端末</td>\n",
       "      <td>サーバ 必要 設定 事項</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>サーバ 必要 設定 事項</td>\n",
       "      <td>必須 接続 プロファイル 作成</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>必須 接続 プロファイル 作成</td>\n",
       "      <td>service サーバ 間 ad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Query                Prediction\n",
       "0  mobicontrol manual mobicontrol manual  サブタイトル 設定 mobicontrol 設定\n",
       "1               サブタイトル 設定 mobicontrol 設定      mobicontrol 設定 順序 端末\n",
       "2                   mobicontrol 設定 順序 端末              サーバ 必要 設定 事項\n",
       "3                           サーバ 必要 設定 事項           必須 接続 プロファイル 作成\n",
       "4                        必須 接続 プロファイル 作成          service サーバ 間 ad"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1, col2 = create_dataset(sentTwo)\n",
    "#col1 = col1.reshape(-1)\n",
    "col2 = col2.reshape(-1,1)\n",
    "#col2.shape\n",
    "dt = np.concatenate((col1,col2), axis=1)\n",
    "\n",
    "lines = pd.DataFrame(dt, columns=['Query', 'Prediction'])\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_ZqeO90TMAp"
   },
   "outputs": [],
   "source": [
    "collector = []\n",
    "for line in lines:\n",
    "    collector.append(line.split())\n",
    "\n",
    "question = []\n",
    "answer = []\n",
    "for items in collector:\n",
    "    # print(items)\n",
    "    shifted_df = (series_to_supervised(items, 4, 4))\n",
    "    for i in range(len(shifted_df)):\n",
    "        saver = shifted_df.iloc[i].values.tolist()\n",
    "        length = len(saver)//2\n",
    "        question.append(saver[:length])\n",
    "        answer.append(saver[length:]) \n",
    "    #break\n",
    "\n",
    "collect_question = []\n",
    "for items in question:\n",
    "    collect_question.append(' '.join(items))\n",
    "collect_answer = []\n",
    "for items in answer:\n",
    "    collect_answer.append(' '.join(items))    \n",
    "\n",
    "lines = pd.DataFrame(zip(collect_question, collect_answer), columns=['Query', 'Prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWfU-bW106ie"
   },
   "outputs": [],
   "source": [
    "lines.Prediction = lines.Prediction.apply(lambda x : '<START> '+ x + ' <END>')\n",
    "lines.head()\n",
    "lines.to_csv('seq2seq_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZ7lsxHYmXVE"
   },
   "outputs": [],
   "source": [
    "lines = pd.read_csv('seq2seq_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "oTmNrsGFysDF",
    "outputId": "0195991d-2a8e-4e36-c974-d724fdd6dafb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mobicontrol manual mobicontrol manual</td>\n",
       "      <td>&lt;START&gt; サブタイトル 設定 mobicontrol 設定 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>サブタイトル 設定 mobicontrol 設定</td>\n",
       "      <td>&lt;START&gt; mobicontrol 設定 順序 端末 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mobicontrol 設定 順序 端末</td>\n",
       "      <td>&lt;START&gt; サーバ 必要 設定 事項 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>サーバ 必要 設定 事項</td>\n",
       "      <td>&lt;START&gt; 必須 接続 プロファイル 作成 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>必須 接続 プロファイル 作成</td>\n",
       "      <td>&lt;START&gt; service サーバ 間 ad &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Query  \\\n",
       "0           0  mobicontrol manual mobicontrol manual   \n",
       "1           1               サブタイトル 設定 mobicontrol 設定   \n",
       "2           2                   mobicontrol 設定 順序 端末   \n",
       "3           3                           サーバ 必要 設定 事項   \n",
       "4           4                        必須 接続 プロファイル 作成   \n",
       "\n",
       "                               Prediction  \n",
       "0  <START> サブタイトル 設定 mobicontrol 設定 <END>  \n",
       "1      <START> mobicontrol 設定 順序 端末 <END>  \n",
       "2              <START> サーバ 必要 設定 事項 <END>  \n",
       "3           <START> 必須 接続 プロファイル 作成 <END>  \n",
       "4          <START> service サーバ 間 ad <END>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mobicontrol manual mobicontrol manual</td>\n",
       "      <td>&lt;START&gt; サブタイトル 設定 mobicontrol 設定 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>サブタイトル 設定 mobicontrol 設定</td>\n",
       "      <td>&lt;START&gt; mobicontrol 設定 順序 端末 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mobicontrol 設定 順序 端末</td>\n",
       "      <td>&lt;START&gt; サーバ 必要 設定 事項 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>サーバ 必要 設定 事項</td>\n",
       "      <td>&lt;START&gt; 必須 接続 プロファイル 作成 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>必須 接続 プロファイル 作成</td>\n",
       "      <td>&lt;START&gt; service サーバ 間 ad &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Query  \\\n",
       "0           0  mobicontrol manual mobicontrol manual   \n",
       "1           1               サブタイトル 設定 mobicontrol 設定   \n",
       "2           2                   mobicontrol 設定 順序 端末   \n",
       "3           3                           サーバ 必要 設定 事項   \n",
       "4           4                        必須 接続 プロファイル 作成   \n",
       "\n",
       "                               Prediction  \n",
       "0  <START> サブタイトル 設定 mobicontrol 設定 <END>  \n",
       "1      <START> mobicontrol 設定 順序 端末 <END>  \n",
       "2              <START> サーバ 必要 設定 事項 <END>  \n",
       "3           <START> 必須 接続 プロファイル 作成 <END>  \n",
       "4          <START> service サーバ 間 ad <END>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.head()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2FfKYJThlkV"
   },
   "outputs": [],
   "source": [
    "data = \" \".join(lines.Query.values.tolist() + lines.Prediction.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "o_dMJJ3Khw4X",
    "outputId": "d3c678c6-44e8-4529-d031-f18d5843912e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobicontrol manual mobicontrol manual サブタイトル 設定 mobicontrol 設定 mobicontrol 設定 順序 端末 サーバ 必要 設定 事項 必須 接続 プロファイル 作成 <START> サブタイトル 設定 mobicontrol 設定 <END> <START> mobicontrol 設定 順序 端末 <END> <START> サーバ 必要 設定 事項 <END> <START> 必須 接続 プロファイル 作成 <END> <START> service サーバ 間 ad <END>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0XWfBoakSrC"
   },
   "outputs": [],
   "source": [
    "f = open(\"dataset_seq2seq.txt\", \"w\")\n",
    "f.write(data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w0CLQvNAkdkQ"
   },
   "outputs": [],
   "source": [
    "f = open(\"dataset_seq2seq.txt\", \"r\")\n",
    "mydata = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tiLP1JYNky6R",
    "outputId": "3a564479-b9a5-4cf2-b9c0-42e087076ed8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'mobicontrol manual mobicontrol manual manual mobicontrol manual カスタマイザー mobicontrol manual カスタマイザー タ'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Lj8y5GfrTO9Z",
    "outputId": "03f65655-0972-49b9-eeec-0551009ac2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 19\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( data.split())\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "pzZD5bd4UpNs",
    "outputId": "49babacb-28ee-46ad-8fd5-618977e53133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "設定\n",
      "mobicontrol\n",
      "start\n",
      "end\n",
      "サーバ\n",
      "manual\n",
      "サブタイトル\n",
      "順序\n",
      "端末\n",
      "必要\n",
      "事項\n",
      "必須\n",
      "接続\n",
      "プロファイル\n",
      "作成\n",
      "service\n",
      "間\n",
      "ad\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for items in tokenizer.word_index:\n",
    "    print(items)\n",
    "    if c>20:\n",
    "        break\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iS0aZR3yZAwJ",
    "outputId": "31d2c90f-bf27-4005-fc4d-474120f90e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4) 4\n",
      "(5, 6) 6\n"
     ]
    }
   ],
   "source": [
    "questions = lines.Query \n",
    "answers = lines.Prediction\n",
    "\n",
    "# encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print( encoder_input_data.shape , maxlen_questions )\n",
    "\n",
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max([ len(x) for x in tokenized_answers ])\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )\n",
    "\n",
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0j2rmdHjZT98"
   },
   "outputs": [],
   "source": [
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XtqiRYQbU2iU",
    "outputId": "61ef46e4-9576-4f67-c2f7-80f697ac0832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 19)\n"
     ]
    }
   ],
   "source": [
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "uXa_8DeBWqMI",
    "outputId": "4a5038d2-5296-4232-de29-4001391c0943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 100)    1900        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 100)    1900        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 100), (None, 80400       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 100),  80400       embedding_5[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 19)     1919        lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 166,519\n",
      "Trainable params: 166,519\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "shape = 100\n",
    "\n",
    "encoder_inputs = Input(shape=( None , ))\n",
    "encoder_embedding = Embedding( VOCAB_SIZE, shape , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = LSTM( shape , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = Input(shape=( None ,  ))\n",
    "decoder_embedding = Embedding( VOCAB_SIZE, shape , mask_zero=True) (decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM( shape , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIXWsw24W328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 700us/step - loss: 2.9470\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 626us/step - loss: 2.9155\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 661us/step - loss: 2.8860\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 723us/step - loss: 2.8487\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 814us/step - loss: 2.7953\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 629us/step - loss: 2.7116\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 747us/step - loss: 2.5734\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 715us/step - loss: 2.3796\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 812us/step - loss: 2.2633\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 698us/step - loss: 2.2062\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 731us/step - loss: 2.1582\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 683us/step - loss: 2.1128\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 681us/step - loss: 2.0667\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 671us/step - loss: 2.0237\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 646us/step - loss: 1.9877\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 634us/step - loss: 1.9693\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 807us/step - loss: 1.9337\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 661us/step - loss: 1.8954\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 632us/step - loss: 1.8508\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 723us/step - loss: 1.8148\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 664us/step - loss: 1.7835\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 679us/step - loss: 1.7570\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 725us/step - loss: 1.7384\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 631us/step - loss: 1.7128\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 726us/step - loss: 1.6922\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 654us/step - loss: 1.6535\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 862us/step - loss: 1.6268\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 775us/step - loss: 1.5929\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 710us/step - loss: 1.5700\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 647us/step - loss: 1.5404\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 672us/step - loss: 1.5225\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 669us/step - loss: 1.4909\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 825us/step - loss: 1.4726\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 894us/step - loss: 1.4347\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 770us/step - loss: 1.4124\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 657us/step - loss: 1.3749\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 744us/step - loss: 1.3526\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 673us/step - loss: 1.3185\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 639us/step - loss: 1.2992\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 900us/step - loss: 1.2665\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 660us/step - loss: 1.2497\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 602us/step - loss: 1.2154\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 574us/step - loss: 1.1982\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 652us/step - loss: 1.1626\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 546us/step - loss: 1.1446\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 791us/step - loss: 1.1106\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 659us/step - loss: 1.0935\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 652us/step - loss: 1.0618\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 637us/step - loss: 1.0468\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 654us/step - loss: 1.0161\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 684us/step - loss: 1.0028\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 701us/step - loss: 0.9713\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 696us/step - loss: 0.9579\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 675us/step - loss: 0.9259\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 889us/step - loss: 0.9118\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 646us/step - loss: 0.8813\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 784us/step - loss: 0.8674\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 756us/step - loss: 0.8395\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 715us/step - loss: 0.8273\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 705us/step - loss: 0.8015\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7913\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 758us/step - loss: 0.7661\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 714us/step - loss: 0.7568\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 635us/step - loss: 0.7308\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 766us/step - loss: 0.7205\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 667us/step - loss: 0.6945\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6832\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 606us/step - loss: 0.6591\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.6482\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 743us/step - loss: 0.6269\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.6178\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 634us/step - loss: 0.5985\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.5916\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 649us/step - loss: 0.5724\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.5661\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 741us/step - loss: 0.5453\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 833us/step - loss: 0.5373\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 650us/step - loss: 0.5161\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 633us/step - loss: 0.5067\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 812us/step - loss: 0.4878\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 639us/step - loss: 0.4788\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 689us/step - loss: 0.4628\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 813us/step - loss: 0.4556\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 642us/step - loss: 0.4418\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 634us/step - loss: 0.4370\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 673us/step - loss: 0.4243\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4221\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 595us/step - loss: 0.4083\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 649us/step - loss: 0.4056\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 623us/step - loss: 0.3868\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 640us/step - loss: 0.3780\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 644us/step - loss: 0.3587\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.3480\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 701us/step - loss: 0.3347\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 661us/step - loss: 0.3262\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 664us/step - loss: 0.3168\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 656us/step - loss: 0.3115\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.3046\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 633us/step - loss: 0.3034\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.2959\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=10, epochs=100) \n",
    "model.save( 'model.h5' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYNFeI5SQJ0i"
   },
   "outputs": [],
   "source": [
    "model = models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "wQYURN33W8MA",
    "outputId": "ad11b51d-54dd-464d-8cea-755de84f7c76"
   },
   "outputs": [],
   "source": [
    "enc_model, dec_model = make_inference_models()\n",
    "\n",
    "states_values = enc_model.predict(str_to_tokens( input( 'Enter question : ' )))\n",
    "empty_target_seq = np.zeros((1, 1 ))\n",
    "empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "stop_condition = False\n",
    "decoded_translation = ''\n",
    "while not stop_condition :\n",
    "    dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "    print('dec_outputs :', dec_outputs)\n",
    "    sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "    print('sampled_word_index: ', sampled_word_index)\n",
    "    \n",
    "    sampled_word = None\n",
    "    for word , index in tokenizer.word_index.items() :\n",
    "        if sampled_word_index == index :\n",
    "            decoded_translation += ' {}'.format( word )\n",
    "            sampled_word = word\n",
    "\n",
    "    if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "        stop_condition = True\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "    empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "    states_values = [ h , c ] \n",
    "\n",
    "print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mobicontrol manual mobicontrol manual</td>\n",
       "      <td>&lt;START&gt; サブタイトル 設定 mobicontrol 設定 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>サブタイトル 設定 mobicontrol 設定</td>\n",
       "      <td>&lt;START&gt; mobicontrol 設定 順序 端末 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mobicontrol 設定 順序 端末</td>\n",
       "      <td>&lt;START&gt; サーバ 必要 設定 事項 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>サーバ 必要 設定 事項</td>\n",
       "      <td>&lt;START&gt; 必須 接続 プロファイル 作成 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>必須 接続 プロファイル 作成</td>\n",
       "      <td>&lt;START&gt; service サーバ 間 ad &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Query  \\\n",
       "0           0  mobicontrol manual mobicontrol manual   \n",
       "1           1               サブタイトル 設定 mobicontrol 設定   \n",
       "2           2                   mobicontrol 設定 順序 端末   \n",
       "3           3                           サーバ 必要 設定 事項   \n",
       "4           4                        必須 接続 プロファイル 作成   \n",
       "\n",
       "                               Prediction  \n",
       "0  <START> サブタイトル 設定 mobicontrol 設定 <END>  \n",
       "1      <START> mobicontrol 設定 順序 端末 <END>  \n",
       "2              <START> サーバ 必要 設定 事項 <END>  \n",
       "3           <START> 必須 接続 プロファイル 作成 <END>  \n",
       "4          <START> service サーバ 間 ad <END>  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQCo1G26TOti"
   },
   "outputs": [],
   "source": [
    "shape = 100\n",
    "\n",
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=( shape ,))\n",
    "    decoder_state_input_c = Input(shape=( shape ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n",
    "    \n",
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    #return tokens_list\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n",
    "\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = []\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def page_text_split(page_text, word_limit):\n",
    "    page_text = page_text.split()\n",
    "    chunks = [' '.join(page_text[i:i + word_limit]) for i in range(0,\n",
    "                                                                   len(page_text), word_limit)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def single_character_remover(text):\n",
    "    collector = []\n",
    "    for items in text.split():\n",
    "        if len(items) < 2:\n",
    "            replaced = re.sub(r'[ぁ-んァ-ン]', '', items)\n",
    "            replaced = re.sub(r'[A-Za-z]', '', replaced)\n",
    "            replaced = re.sub(r'[0-9]', '', replaced)\n",
    "            collector.append(replaced)\n",
    "        else:\n",
    "            collector.append(items)\n",
    "\n",
    "    return ' '.join([temp.strip(' ') for temp in collector])\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seq2Seq_mobicontrol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
