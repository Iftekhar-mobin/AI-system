{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches, SequenceMatcher\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "dataset = 'deep_clean_mobicontrol_data.txt'\n",
    "hira_kata = 'かめふアうチパズヅさモぴグゆごヒサもシマりはゲひべヘイヤづペユへぽのほけエこツぺぢだをデどヨギぜミキリるろヌばむょラゴにウずしてすぬつスコネせムロたちゾぎゃおピぶンねガヲぱらカダメュョぷそナみノなんクホハニぞトでげワいャぐとザビやソプれぼきバベブジゅじゼまレセルびポがくわタドオケヂフボテえざあよ'\n",
    "eng_letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "all_letters = hira_kata + eng_letters\n",
    "WORDS = Counter(words(open(dataset).read()))\n",
    "\n",
    "with open('/home/iftekhar/amiebot/exp_amiecore/amieCore/amie_core/core/retriever/Page_Ranking_Experiment'\n",
    "          '/pipelines/vocabulary.txt') as f:\n",
    "    vocabulary = f.read().splitlines()\n",
    "\n",
    "collector = []\n",
    "for items in vocabulary:\n",
    "    items = items.lower()\n",
    "    collector.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_file = Path(\"/home/iftekhar/AI-system/Helpers/Mixed/POL_workshop/processed_texts.txt\")\n",
    "with open(data_file, encoding='utf-8') as f:\n",
    "    data_list = f.read().splitlines()\n",
    "all_text = single_character_remover(\" \".join(data_list))\n",
    "\n",
    "f = open('deep_clean_mobicontrol_data.txt', 'w')\n",
    "f.write(all_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_character_remover(text):\n",
    "    collector = []\n",
    "    for items in text.split():\n",
    "        if len(items) < 2:\n",
    "            replaced = re.sub(r'[ぁ-んァ-ン]', '', items)\n",
    "            replaced = re.sub(r'[A-Za-z]', '', replaced)\n",
    "            replaced = re.sub(r'[0-9]', '', replaced)\n",
    "            collector.append(replaced)\n",
    "        else:\n",
    "            collector.append(items)\n",
    "\n",
    "    return ' '.join([temp.strip(' ') for temp in collector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_substrings(string):\n",
    "    n = len(string)\n",
    "    return {string[i:j+1] for i in range(n) for j in range(i,n)}\n",
    "\n",
    "def longest_match(best_matches, items):\n",
    "    longest_content = []\n",
    "    for content in best_matches: \n",
    "        longest_content.append(max(all_substrings(content) & all_substrings(items), key=len))\n",
    "    return max(longest_content, key=len)\n",
    "\n",
    "def handling_spelling_mistakes(misspelled_word, vocabulary):\n",
    "    max_term = []\n",
    "    best_matches = get_close_matches(misspelled_word, vocabulary, n = 5, cutoff = 0.6)\n",
    "    if best_matches:\n",
    "        max_term = longest_match(best_matches, items)\n",
    "    return max_term\n",
    "\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def probability(word, N=sum(WORDS.values())): \n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=probability)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    letters    = all_letters\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide a input: num hello bht データトラフィック 規定 moibicontrols asfasdf\n"
     ]
    }
   ],
   "source": [
    "sent = input(\"Provide a input: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobicontrol\n",
      "{'mobicontrole', 'mobicontrol'}\n",
      "Unknown word asfasdf\n"
     ]
    }
   ],
   "source": [
    "sent_list = sent.split()\n",
    "for items in sent_list:\n",
    "    items = items.lower()\n",
    "    if items not in collector:\n",
    "        matches = handling_spelling_mistakes(items, collector)\n",
    "        match_len = len(matches)/len(items)\n",
    "        # print(match_len, len(items), len(matches))\n",
    "        if  match_len > 0.8 and SequenceMatcher(None, items, matches).ratio() > 0.7:\n",
    "            print(\"Correct Spelling: \", matches)\n",
    "        elif SequenceMatcher(None, items, matches).ratio() > 0.5:              \n",
    "            spelling = correction(items)\n",
    "            if spelling != items:\n",
    "                print(spelling)\n",
    "                print(known(edits2(items)))\n",
    "        # else:\n",
    "        #      print('Unknown word', items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'クリック'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('クリッ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'エリア',\n",
       " 'クラス',\n",
       " 'クリア',\n",
       " 'クリック',\n",
       " 'クリップ',\n",
       " 'クルマ',\n",
       " 'グリフ',\n",
       " 'スクリプ',\n",
       " 'フリック',\n",
       " 'ブリッジ',\n",
       " 'メリット'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known(edits2('クリッ'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
