{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.soti.net/resources/events/'\n",
    "length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(requests.get(url).content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in soup.findAll('img'):\n",
    "    print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 32/32 [00:00<00:00, 12836.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://soti.net/media/1897/stock_guy_75x75.png\n",
      "https://www.soti.net/media/2038/new-soti-one-diagram.png\n",
      "https://www.soti.net/media/1086/products_menu_mc.jpg\n",
      "https://www.soti.net/media/1720/products_menu_assist2.jpg\n",
      "https://www.soti.net/media/1721/products_menu_snap2.jpg\n",
      "https://www.soti.net/media/2103/products_menu_insight.jpg\n",
      "https://www.soti.net/media/2115/products_menu_connect.jpg\n",
      "https://www.soti.net/media/2113/products_menu_identity.jpg\n",
      "https://www.soti.net/media/2114/products_menu_central.jpg\n",
      "https://www.soti.net/media/1384/pocket_controller.png\n",
      "https://www.soti.net/media/2641/dropdown-emergencyservices.jpg\n",
      "https://www.soti.net/media/2645/dropdown-retail.jpg\n",
      "https://www.soti.net/media/2646/dropdown-tl.jpg\n",
      "https://www.soti.net/media/2648/dropdown-fieldservices.jpg\n",
      "https://www.soti.net/media/2647/dropdown-healthcare.jpg\n",
      "https://www.soti.net/media/1363/altitude_logo.png\n",
      "https://www.soti.net/media/1739/casio.png\n",
      "https://www.soti.net/media/1369/datalogic400.png\n",
      "https://www.soti.net/media/1370/honeywell400.png\n",
      "https://www.soti.net/media/1374/panasonic400.png\n",
      "https://www.soti.net/media/1829/sato_logo.png\n",
      "https://www.soti.net/media/1375/samsung400.png\n",
      "https://www.soti.net/media/1376/zebra400.png\n",
      "https://www.soti.net/media/3460/ruan-transportation.png\n",
      "https://www.soti.net/media/3749/5fieldservicesmobilitychallenges-dropdown.jpg\n",
      "http://www2.soti.net/l/35942/2019-11-26/299zr9q/35942/287995/IT_logo_site_265x125.png\n",
      "http://www2.soti.net/l/35942/2019-12-18/29sbmlz/35942/289369/SOTI___600Minutes_Executive_IT_2020.png\n",
      "http://www2.soti.net/l/35942/2019-12-09/29mm6pv/35942/288605/NEXT_logo_black_webb.png\n",
      "http://www2.soti.net/gitex19\n",
      "http://www2.soti.net/l/35942/2020-06-29/2gnysfj/35942/307267/NRF_2021_Logo.PNG\n",
      "https://px.ads.linkedin.com/collect/?pid=1277636&fmt=gif\n",
      "https://www.facebook.com/tr?id=570393336699758&ev=PageView&noscript=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(soup.find_all(\"img\"), \"Extracting images\"):\n",
    "    img_url = img.attrs.get(\"src\")\n",
    "    if not img_url:\n",
    "        # if img does not contain src attribute, just skip\n",
    "        continue\n",
    "    # make the URL absolute by joining domain with the URL that is just extracted\n",
    "    img_url = urljoin(url, img_url)\n",
    "    print(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntroduction.html#lists\">More about lists in Python&nbsp;3</a></p></div>\n",
      "                </li>\n",
      "          +++++++\n",
      "thmetic</span>\n",
      "&gt;&gt;&gt; 1 / 2\n",
      "<span class=\"output\">0.5</span>\n",
      "&gt;&gt;&gt; 2 ** 3\n",
      "<span class=\"outp +++++++\n",
      "readmore\" href=\"/doc/\">Learn More</a></p>\n",
      "        </div>\n",
      "\n",
      "\n",
      "             </div><!-- end .container -->\n",
      "  +++++++\n",
      "<h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-get-started\"></span>Get Started</h2>\n",
      "<p>W +++++++\n",
      ">\n",
      "<p>Python source code and installers are available for download for all versions!</p>\n",
      "<p>Latest: <a h +++++++\n",
      ".org\">docs.python.org</a></p>\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"small-widget  +++++++\n",
      "/div>\n",
      "\n",
      "                <div class=\"list-widgets row\">\n",
      "\n",
      "                    <div class=\"medium-widget bl +++++++\n",
      "               <ul class=\"menu\">\n",
      "                                \n",
      "                                \n",
      "     +++++++\n",
      "0-</span>08-17</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/yowZpdqeW1I/python-379- +++++++\n",
      " available</a></li>\n",
      "                                \n",
      "                                <li>\n",
      "<time datetim +++++++\n",
      "-more\">2020-</span>07-27</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~ +++++++\n",
      "                   <td><p><a href=\"/success-stories/python-for-financial-machine-learning-at-union-inve +++++++\n",
      "t-title\"><span aria-hidden=\"true\" class=\"icon-python\"></span>Use Python for…</h2>\n",
      "<p class=\"give-me-mor +++++++\n",
      " class=\"tag\" href=\"http://www.web2py.com/\">web2py</a></span></li>\n",
      "    <li><b>GUI Development</b>:\n",
      "      +++++++\n",
      "\">\n",
      "<a class=\"tag\" href=\"http://www.scipy.org\">SciPy</a>, <a class=\"tag\" href=\"http://pandas.pydata.org/ +++++++\n",
      "ack.com\">Salt</a>, <a class=\"tag\" href=\"https://www.openstack.org\">OpenStack</a></span></li>\n",
      "</ul>\n",
      "\n",
      "    +++++++\n",
      "r</a>\n",
      "    <a class=\"button\" href=\"/psf/donations/\">Donate to the PSF</a>\n",
      "</p>\n",
      "                </div>\n",
      "\n",
      "\n",
      " +++++++\n",
      "ass=\"container\">\n",
      "\n",
      "                    \n",
      "                    <a id=\"back-to-top-1\" class=\"jump-link\" href +++++++\n",
      "jump-link\" href=\"#python-network\"><span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>▲</span></span>  +++++++\n",
      "an> Back to Top</a>\n",
      "\n",
      "                    \n",
      "\n",
      "<ul class=\"sitemap navigation menu do-not-print\" role=\"tree\" +++++++\n",
      "id=\"container\" style=\"position: relative; height: 930.094px;\">\n",
      "    \n",
      "    <li class=\"tier-1 element-1\" st +++++++\n",
      "ment-1\" style=\"position: absolute; left: 0px; top: 0px;\">\n",
      "        <a href=\"/about/\">About</a>\n",
      "        \n",
      " +++++++\n",
      "\n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a hr +++++++\n",
      "a href=\"/about/apps/\" title=\"\">Applications</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"tr +++++++\n",
      "-2\" role=\"treeitem\"><a href=\"/about/quotes/\" title=\"\">Quotes</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 el +++++++\n",
      "ier-2 element-3\" role=\"treeitem\"><a href=\"/about/gettingstarted/\" title=\"\">Getting Started</a></li>\n",
      "    +++++++\n",
      "Visual Talks</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"https://wiki.p +++++++\n",
      "class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"http://wiki.python.org/moin/Languages\" title=\"\">Non-E +++++++\n",
      "le=\"success-stories\">Success Stories</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        < +++++++\n",
      "  \n",
      "    <li class=\"tier-1 element-6\" style=\"position: absolute; left: 501px; top: 405px;\">\n",
      "        <a hr +++++++\n",
      ">\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treei +++++++\n",
      "\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeit +++++++\n",
      "s=\"icon-arrow-up\"><span>▲</span></span> Back to Top</a>\n",
      "                    \n",
      "\n",
      "                </div><!- +++++++\n",
      " +++++++\n",
      " +++++++\n",
      " +++++++\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for match in re.finditer('img', str(soup.contents)):\n",
    "    if match:\n",
    "        print(source[match.start() - length: match.end() + length], '+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "\n",
    "def is_valid(url):\n",
    "    \"\"\"\n",
    "    Checks whether `url` is a valid URL.\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)\n",
    "\n",
    "\n",
    "def get_all_images(url):\n",
    "    \"\"\"\n",
    "    Returns all image URLs on a single `url`\n",
    "    \"\"\"\n",
    "    soup = bs(requests.get(url).content, \"html.parser\")\n",
    "    urls = []\n",
    "    for img in tqdm(soup.find_all(\"img\"), \"Extracting images\"):\n",
    "        img_url = img.attrs.get(\"src\")\n",
    "        if not img_url:\n",
    "            # if img does not contain src attribute, just skip\n",
    "            continue\n",
    "        # make the URL absolute by joining domain with the URL that is just extracted\n",
    "        img_url = urljoin(url, img_url)\n",
    "        # remove URLs like '/hsts-pixel.gif?c=3.2.5'\n",
    "        try:\n",
    "            pos = img_url.index(\"?\")\n",
    "            img_url = img_url[:pos]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # finally, if the url is valid\n",
    "        if is_valid(img_url):\n",
    "            urls.append(img_url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def download(url, pathname):\n",
    "    \"\"\"\n",
    "    Downloads a file given an URL and puts it in the folder `pathname`\n",
    "    \"\"\"\n",
    "    # if path doesn't exist, make that path dir\n",
    "    if not os.path.isdir(pathname):\n",
    "        os.makedirs(pathname)\n",
    "    # download the body of response by chunk, not immediately\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # get the total file size\n",
    "    file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "    # get the file name\n",
    "    filename = os.path.join(pathname, url.split(\"/\")[-1])\n",
    "\n",
    "    # progress bar, changing the unit to bytes instead of iteration (default by tqdm)\n",
    "    progress = tqdm(response.iter_content(1024), f\"Downloading {filename}\", total=file_size, unit=\"B\", unit_scale=True, unit_divisor=1024)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for data in progress:\n",
    "            # write data read to the file\n",
    "            f.write(data)\n",
    "            # update the progress bar manually\n",
    "            progress.update(len(data))\n",
    "\n",
    "\n",
    "def main(url, path):\n",
    "    # get all images\n",
    "    imgs = get_all_images(url)\n",
    "    for img in imgs:\n",
    "        # for each img, download it\n",
    "        download(img, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 9/9 [00:00<00:00, 23592.96it/s]\n",
      "Downloading /home/iftekhar/747ffa5da3538e66840ebc0548b8fd58:   0%|          | 3.00/2.84k [00:00<00:03, 854B/s]\n",
      "Downloading /home/iftekhar/4eceaeb8bad76db25745becc2dc30406:   0%|          | 3.00/2.68k [00:00<00:03, 885B/s]\n",
      "Downloading /home/iftekhar/4c4ba854e95bafdbab0a95326b06eb11:   0%|          | 3.00/2.58k [00:00<00:03, 774B/s]\n",
      "Downloading /home/iftekhar/1a3a8e55d66efa9bb6d5b36cd92ba9d7:   0%|          | 3.00/2.58k [00:00<00:02, 909B/s]\n",
      "Downloading /home/iftekhar/9dcd6d5fe63666f1c40049c364076ee7:   0%|          | 4.00/3.40k [00:00<00:03, 914B/s]\n",
      "Downloading /home/iftekhar/3acb8bae5a2b5a28f6fe522a4ea9b873:   0%|          | 11.0/10.7k [00:00<00:04, 2.58kB/s]\n",
      "Downloading /home/iftekhar/a3afcf08cd317313539eeca4b605c0ad:   0%|          | 3.00/2.58k [00:00<00:03, 775B/s]\n",
      "Downloading /home/iftekhar/cb51: 0.00B [00:00, ?B/s]\n",
      "Downloading /home/iftekhar/p-c1rF4kxgLUzNc.gif:   3%|▎         | 1.00/35.0 [00:00<00:00, 320B/s]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://stackoverflow.com/questions/257409/download-image-file-from-the-html-page-source-using-python'\n",
    "path = '/home/iftekhar'\n",
    "main(url, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(url):\n",
    "    \"\"\"\n",
    "    Checks whether `url` is a valid URL.\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)\n",
    "\n",
    "\n",
    "def get_all_images(url):\n",
    "    \"\"\"\n",
    "    Returns all image URLs on a single `url`\n",
    "    \"\"\"\n",
    "    soup = bs(requests.get(url).content, \"html.parser\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    urls = []\n",
    "    for img in tqdm(soup.find_all(\"img\"), \"Extracting images\"):\n",
    "        img_url = img.attrs.get(\"src\")\n",
    "        if not img_url:\n",
    "            # if img does not contain src attribute, just skip\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 83.0.4103\n",
      "[WDM] - Get LATEST driver version for 83.0.4103\n",
      "[WDM] - Get LATEST driver version for 83.0.4103\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_linux64.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver has been saved in cache [/home/iftekhar/.wdm/drivers/chromedriver/linux64/83.0.4103.39]\n",
      "/home/iftekhar/amiebot/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: use options instead of chrome_options\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n",
    "driver.get('https://python.org')\n",
    "driver.save_screenshot(\"screenshot2.png\")\n",
    "\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = driver.page_source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(source)\n",
    "\n",
    "for img in soup.findAll('img'):\n",
    "    print(img)\n",
    "    request.urlretrieve(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/static/img/python-logo.png']\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for img in soup.findAll('img'):\n",
    "    images.append(img.get('src'))\n",
    "\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/img/python-logo.png\n"
     ]
    }
   ],
   "source": [
    "img_tags = soup.find_all('img')\n",
    "urls = [img['src'] for img in img_tags]\n",
    "\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all content in a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "html = urllib.request.urlopen(url).read()\n",
    "print(text_from_html(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
