{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8T7iS8zWQlFr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow.keras\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3m_AGIWodq7y",
    "outputId": "39492db2-e251-4477-d5ca-af3de5990fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0-rc3\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "qkth5pLXd_MO",
    "outputId": "8519f057-d208-433c-9a81-d5114bdcba0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: 10.74.220.2:8470\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.74.220.2:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12000591522883152549)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7709529895786582810)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6675122616251050432)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16386696429296309467)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14593359885882312184)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 3746470190846554936)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3235103592666986621)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1854734206916537060)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5247770345368463529)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2718152276426878486)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12564736273146274800)\n",
      "Running on TPU  ['10.74.220.2:8470']\n",
      "Number of accelerators:  8\n"
     ]
    }
   ],
   "source": [
    "# Donanım Tanı\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU tanı\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Uygun dağıtım stratejisini seçin\n",
    "if tpu:\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu, steps_per_run=128) #TPU ile sunucu arasında ileri geri gitmek pahalıdır. Rapor vermeden önce TPU'da 128 parti çalıştırmak daha iyidir.\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
    "elif len(gpus) > 1:\n",
    "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
    "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "  strategy = tf.distribute.get_strategy() # CPU ve tek GPU'da çalışan varsayılan strateji\n",
    "  print('Running on single GPU ', gpus[0].name)\n",
    "else:\n",
    "  strategy = tf.distribute.get_strategy() # CPU ve tek GPU'da çalışan varsayılan strateji\n",
    "  print('Running on CPU')\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbPWkxroeX4r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NGQOk936QlGn",
    "outputId": "4c93fe31-57b4-404d-a34d-1470c3fc7238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t6ZXnvOVRkbj",
    "outputId": "1b366927-84a8-40dd-a886-84da1eaa2a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMF9reuuQlGs"
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('processed_len_10.csv')\n",
    "\n",
    "#reducing data sample size\n",
    "res = result.sample(frac=0.01).reset_index(drop=True)\n",
    "\n",
    "#\n",
    "#res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5BiAGgVbfS_W",
    "outputId": "0de6cf33-cb62-47f2-f740-55331a6ac953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67251"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G6w-_RyTnan"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "result = shuffle(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CcYx2h1QlG0"
   },
   "outputs": [],
   "source": [
    "tog = result.iloc[:,:-1].apply(lambda x: ' '.join(x), axis=1)\n",
    "#tog.to_csv(\"tog.csv\")\n",
    "input_texts = list(tog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCHaOy52QlG7"
   },
   "outputs": [],
   "source": [
    "target = result.iloc[:,-1].apply(lambda x: str(x))\n",
    "target_texts = list(target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZipdyXBmQlHB"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of Input words\n",
    "all_input_words=set()\n",
    "for jap in input_texts:\n",
    "    for word in jap.split():\n",
    "        if word not in all_input_words:\n",
    "            all_input_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Ae6aQuYQlHL",
    "outputId": "19f29635-3562-4f86-d130-52c54dba3235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfecf-BPQlHP"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of Input characters\n",
    "input_characters=set()\n",
    "for input_text in input_texts:    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jCLD_L-ZQlHU",
    "outputId": "3e2a04f2-67f7-4470-81e1-731a52508f30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoPYLXALQlHa"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of target character\n",
    "target_characters=set()\n",
    "for target_text in target_texts:    \n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YVFjBSWnQlHe",
    "outputId": "c918d281-d3e2-46f7-b343-923a433d462d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "plAumHpyQlHj",
    "outputId": "ecd8fc6a-9734-4b5e-dd4b-90457442ab4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 673\n",
      "Number of unique input tokens: 648\n",
      "Number of unique output tokens: 10\n",
      "Max sequence length for inputs: 72\n",
      "Max sequence length for outputs: 3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNZd89LJgEuL"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPyF2YKGjIOW"
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h-u9Se2tj4XD",
    "outputId": "f914fd82-b575-4821-d466-7624bec45b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TPU at: grpc://10.74.220.2:8470\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  device_name = os.environ['COLAB_TPU_ADDR']\n",
    "  TPU_ADDRESS = 'grpc://' + device_name\n",
    "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
    "\n",
    "except KeyError:\n",
    "  print('TPU not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "4cf91iYCjM4Y",
    "outputId": "66b0a14e-dbab-444c-9ae4-4bc6c84ad54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdhOw3GLiYQa"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# Run training\n",
    "model.compile(tf.train.GradientDescentOptimizer(learning_rate=0.05), \n",
    "              loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k8TjBikbjXFK",
    "outputId": "292c0ec3-a4ca-40e3-be17-9257fc6d39cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 538 samples, validate on 135 samples\n",
      "Epoch 1/100\n",
      "538/538 [==============================] - 12s 22ms/sample - loss: 1.3040 - val_loss: 1.2836\n",
      "Epoch 2/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3036 - val_loss: 1.2835\n",
      "Epoch 3/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3034 - val_loss: 1.2833\n",
      "Epoch 4/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3032 - val_loss: 1.2832\n",
      "Epoch 5/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3029 - val_loss: 1.2831\n",
      "Epoch 6/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3028 - val_loss: 1.2830\n",
      "Epoch 7/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3026 - val_loss: 1.2829\n",
      "Epoch 8/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3024 - val_loss: 1.2828\n",
      "Epoch 9/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3022 - val_loss: 1.2827\n",
      "Epoch 10/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3020 - val_loss: 1.2826\n",
      "Epoch 11/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3019 - val_loss: 1.2825\n",
      "Epoch 12/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3017 - val_loss: 1.2824\n",
      "Epoch 13/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3016 - val_loss: 1.2823\n",
      "Epoch 14/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3015 - val_loss: 1.2822\n",
      "Epoch 15/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3014 - val_loss: 1.2822\n",
      "Epoch 16/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3012 - val_loss: 1.2822\n",
      "Epoch 17/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3011 - val_loss: 1.2821\n",
      "Epoch 18/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3010 - val_loss: 1.2820\n",
      "Epoch 19/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3009 - val_loss: 1.2819\n",
      "Epoch 20/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3008 - val_loss: 1.2819\n",
      "Epoch 21/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3007 - val_loss: 1.2818\n",
      "Epoch 22/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3006 - val_loss: 1.2817\n",
      "Epoch 23/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3005 - val_loss: 1.2817\n",
      "Epoch 24/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3004 - val_loss: 1.2816\n",
      "Epoch 25/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3003 - val_loss: 1.2816\n",
      "Epoch 26/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3002 - val_loss: 1.2816\n",
      "Epoch 27/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3001 - val_loss: 1.2815\n",
      "Epoch 28/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.3000 - val_loss: 1.2814\n",
      "Epoch 29/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2999 - val_loss: 1.2814\n",
      "Epoch 30/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2998 - val_loss: 1.2814\n",
      "Epoch 31/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2997 - val_loss: 1.2813\n",
      "Epoch 32/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2996 - val_loss: 1.2812\n",
      "Epoch 33/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2995 - val_loss: 1.2811\n",
      "Epoch 34/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2995 - val_loss: 1.2811\n",
      "Epoch 35/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2994 - val_loss: 1.2811\n",
      "Epoch 36/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2993 - val_loss: 1.2810\n",
      "Epoch 37/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2992 - val_loss: 1.2809\n",
      "Epoch 38/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2992 - val_loss: 1.2809\n",
      "Epoch 39/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2991 - val_loss: 1.2808\n",
      "Epoch 40/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2990 - val_loss: 1.2808\n",
      "Epoch 41/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2989 - val_loss: 1.2808\n",
      "Epoch 42/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2988 - val_loss: 1.2807\n",
      "Epoch 43/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2988 - val_loss: 1.2806\n",
      "Epoch 44/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2987 - val_loss: 1.2805\n",
      "Epoch 45/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2986 - val_loss: 1.2804\n",
      "Epoch 46/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2986 - val_loss: 1.2804\n",
      "Epoch 47/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2985 - val_loss: 1.2802\n",
      "Epoch 48/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2984 - val_loss: 1.2802\n",
      "Epoch 49/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2984 - val_loss: 1.2802\n",
      "Epoch 50/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2983 - val_loss: 1.2800\n",
      "Epoch 51/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2982 - val_loss: 1.2799\n",
      "Epoch 52/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2981 - val_loss: 1.2798\n",
      "Epoch 53/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2980 - val_loss: 1.2797\n",
      "Epoch 54/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2980 - val_loss: 1.2795\n",
      "Epoch 55/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2979 - val_loss: 1.2794\n",
      "Epoch 56/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2978 - val_loss: 1.2793\n",
      "Epoch 57/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2977 - val_loss: 1.2792\n",
      "Epoch 58/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2977 - val_loss: 1.2791\n",
      "Epoch 59/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2976 - val_loss: 1.2791\n",
      "Epoch 60/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2975 - val_loss: 1.2790\n",
      "Epoch 61/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2974 - val_loss: 1.2790\n",
      "Epoch 62/100\n",
      "538/538 [==============================] - 11s 20ms/sample - loss: 1.2974 - val_loss: 1.2789\n",
      "Epoch 63/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2973 - val_loss: 1.2788\n",
      "Epoch 64/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2972 - val_loss: 1.2787\n",
      "Epoch 65/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2972 - val_loss: 1.2787\n",
      "Epoch 66/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2971 - val_loss: 1.2787\n",
      "Epoch 67/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2970 - val_loss: 1.2787\n",
      "Epoch 68/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2970 - val_loss: 1.2786\n",
      "Epoch 69/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2968 - val_loss: 1.2785\n",
      "Epoch 70/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2968 - val_loss: 1.2784\n",
      "Epoch 71/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2967 - val_loss: 1.2783\n",
      "Epoch 72/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2967 - val_loss: 1.2783\n",
      "Epoch 73/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2966 - val_loss: 1.2782\n",
      "Epoch 74/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2965 - val_loss: 1.2782\n",
      "Epoch 75/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2964 - val_loss: 1.2781\n",
      "Epoch 76/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2963 - val_loss: 1.2780\n",
      "Epoch 77/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2963 - val_loss: 1.2780\n",
      "Epoch 78/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2962 - val_loss: 1.2778\n",
      "Epoch 79/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2961 - val_loss: 1.2778\n",
      "Epoch 80/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2961 - val_loss: 1.2776\n",
      "Epoch 81/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2960 - val_loss: 1.2776\n",
      "Epoch 82/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2959 - val_loss: 1.2775\n",
      "Epoch 83/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2959 - val_loss: 1.2774\n",
      "Epoch 84/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2958 - val_loss: 1.2773\n",
      "Epoch 85/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2957 - val_loss: 1.2773\n",
      "Epoch 86/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2957 - val_loss: 1.2771\n",
      "Epoch 87/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2956 - val_loss: 1.2770\n",
      "Epoch 88/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2955 - val_loss: 1.2769\n",
      "Epoch 89/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2954 - val_loss: 1.2768\n",
      "Epoch 90/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2954 - val_loss: 1.2768\n",
      "Epoch 91/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2953 - val_loss: 1.2766\n",
      "Epoch 92/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2952 - val_loss: 1.2766\n",
      "Epoch 93/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2951 - val_loss: 1.2766\n",
      "Epoch 94/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2951 - val_loss: 1.2765\n",
      "Epoch 95/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2950 - val_loss: 1.2764\n",
      "Epoch 96/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2949 - val_loss: 1.2763\n",
      "Epoch 97/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2949 - val_loss: 1.2763\n",
      "Epoch 98/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2948 - val_loss: 1.2762\n",
      "Epoch 99/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2948 - val_loss: 1.2761\n",
      "Epoch 100/100\n",
      "538/538 [==============================] - 10s 19ms/sample - loss: 1.2947 - val_loss: 1.2760\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dqFNCJQjQlHq",
    "outputId": "cde9736b-b68b-4a10-e2dc-413df5f12d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 時 に 端末 ユーザ が 画面 を 見 て ない\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ルール の 作成 Android の 場合 Android 端末 の 登録\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: に対する ユーザ 名 端末 登録 時 の ユーザ 認証 に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Application Enrollment Token 拡張 子 * XAP の アプリパッケージ を\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 」 固定 文字 列 を 選択 する と 図 が\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ます 端末 の 接続 時間 帯 の 開始 時刻 に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 送ら れ ます 接続 し て ない 場合 は 次\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Canada Translated by Penetrate of Limits Co Ltd Tokyo 上辺\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 設定 は 許す が 強度 の 低い AP に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ルール の 作成 端末 登録 ルール アプリ ･ カタログ ルール\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: さ れ て ない 内部 メモリ の 新規 作成 の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 図 の 証明 書 の タイプ で 「 ユーザー 」\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: で 起動 する 直前 一 日 に 一 回 Microsoft\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 無 接続 端末 対策 端末 証明 書 アプリ の 起動\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Apple DEP サーバ に 登録 し ます ABM 担当 者\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 」 や 「 スケジュール 」 も 修正 でき ます 「\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 構成 プロファイル および パッケージ を 端末 に 送る とき の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: し た 日時 端末 が サーバ と 最後 に 接続\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ファイル を アップ ロード する 前 または 後で 端末 で\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: に 必要 な ファイル を ダウンロード DEP 販売 店 ID\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 端末 ユーザ の 本人 認証 無 接続 端末 対策 アプリ\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: し た とき に 常に 更新 」 に チェック を\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 一定 時間 続く と イントラネットサーバ は 接続 を 切断 し\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: と 「 ｷｬﾝｾﾙ 」 エラー 「 OK 」 PC に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 全体 の 設定 作業 工数 を 減らす こと が でき\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: メール サーバ に SSL 接続 する 場合 は チェック を\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 経過 WIPE を 自己 実行 工場 出荷 状態 に もどす\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: に 伴う 設定 を し ます 管理 プロファイル モード の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: と ログ 上限 図 収集 スケジュール 端末 で 利用 通信\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 登録 ランチャー と テンプレート ランチャー と タグ クルマ 運転\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 改行 し て から 文字 列 表示 < a href\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: は 「 Windows Embedded 端末 の 構成 プロファイル の 作成\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の if 構文 スクリプト は 無視 さ れ て アプリ\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: すぐ 更新 する 端末 状況 を 視る 端末 状況 :\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: さ れ ます 受注 が できれ ば その データ を\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Apple の アクティベーションサーバ に 登録 さ れ て い ます\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 下辺 の 「 次 へ 」 を タップ J J\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を クリック コンソール PC 内 の S MINE の 暗号\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: し ます 当該 プログラム へ の パス を 記述 し\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: に は 実在 する メールアドレス を 使い ます Google アカウント\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ファイル 暗号 化 端末 ユーザ の 本人 認証 無 接続\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 設定 方法 バッテリ 消耗 度 端末 へ の 働きかけ\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の ため に ユーザ 名 を 指定 し ます AD\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 」 を 選択 図 で 「 職場 または 学校 に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Google Play アカウント の 作成 」 の ページ を 参照\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 右側 ペイン に は 当該 PC に関する 情報 が 表示\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 実行 せよ 」 の 意味 サンプル if not exist\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: App ストア から ダウンロード しよ う と し た 場合\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 変わり ます 図 OS Windows Embedded そのもの も ロック 解除\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: : と 記入 し ます この ドメイン の ユーザ を\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: な プルダウンメニュー が 現れ ます この 中 の 「 詳細\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を つける 図 赤 背景 の コラム に 端末 移動\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 図 項 目 名 説 明 自動 入力 を 可能\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ルール の 作成 端末 登録 ルール アプリ ･ カタログ ルール\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ます 従って 電子 メール プロファイル の 種類 も 複数 と\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: する アプリ や ファイル の アイコン や その アイコン に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 変更 構文 writeprivateprofstring Device DeviceName < 新しい 端末 名\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 構成 プロファイル の 追加 」 メニュー 図 の 中 の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 監視 モード に する 仕組み です 監視 モード に する\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 働きかけ の 作業 項目 の 違い について は 下記 の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: アプリ の インストール 方法 端末 ユーザ 自身 で ダウンロード 端末\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 命名 し ます ユーザー が パスワード を 保存 できる\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 外す 構文 registerdll U < DLL の ファイル 名 >\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 端末 を MobiControl に 登録 する とき の 端末 認証\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 更に 下 に サブフォルダ を 作成 し そこ に\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: その メニュー 制限 可能 可能 不可能 可能 ブラウザ Surf の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: : 図 の 再掲 図 で 収集 する 監視 データ\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 詳しく は Windows Modern の 登録 を 参照 ください Windows\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 通知 さ れ ます サンプル foregroundmode disable これから の MobiControl\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: アドレス もしくは ホスト 名 クライアント 証明 書 右端 を プルダウン\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 種類 が あり ます その 中 から 任意 の 項目\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ます 設定 または 変更 が 終り 設定 ダイアログ の 「\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: メニュー が 表示 さ れ ます これから 曜日 を 選択\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Document goto next : next 現在 の フォルダ の 全て\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 設定 」 を 選択 する と 図 が 現れ\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ん そして Apple ID を 入力 し なく て も\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: て 送信 し ます 既存 の スクリプト 文 を 送信\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Exchange の 設定 無線 LAN の 設定 SOTI Hub SOTI\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 端末 の 機能 制限 E メール の 設定 MS Exchange\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: が PC に 存在 する か どう か 構成 証明\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: Tokyo 図 上辺 の 「 Android 」 タブ を 選択\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の フィルター 条件 を 設定 でき ます 図 の 赤\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: グループ 名前 を 入れる と 類推 が し やすく なる\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の 設定 サーバ 群 アクセス 順位 端末 から の 登録\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: フォルダ を 選択 し プロファイル の ファイル を クリック する\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 入れ て おく と 図 の 時刻 C で\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 端末 の 機能 制限 E メール の 設定 MS Exchange\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ロード し ます 上辺 バー から 「 全て の OS\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 選択 図 の ダイアログ が 表示 さ れ ます 通信\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: ルール 端末 の 移動 ルール データ 収集 ルール アラートルール 通信\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 機能 制限 E メール の 設定 MS Exchange ActiveSync IMAP\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 開く 前 に スキャン 検疫 し ます アクセス 時\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: の を 禁止 し ます ダイレクトメモリアクセス を 無効 に し\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 場合 が あり ます 図 の 右 上 に の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 表示 項目 位置 表示 機能 これから の 軌跡 を 描画\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: へ の 連絡 先 時刻 の 同期 更新 スケジュール ルール\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: replacetext < パス と ファイル 名 > < 置換 前\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: SNTP NTP を 使用 し ます SNTP NTP サーバ の\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: 図 レイアウト その他 の 要素 で 希望 する HTML 文書\n",
      "Decoded sentence: 1444\n",
      "-\n",
      "Input sentence: を 描画 ジオフェンス の 作成 と 運用 Android 端末 レポート\n",
      "Decoded sentence: 1444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    #target_seq[0, 0, 0] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0voUTwhQlHu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "seq2seq-Japanese Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
