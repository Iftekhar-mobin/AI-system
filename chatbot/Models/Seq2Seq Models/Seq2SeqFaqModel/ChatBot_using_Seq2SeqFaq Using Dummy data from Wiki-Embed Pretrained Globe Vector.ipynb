{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhwN0XQX4Icu"
   },
   "source": [
    "# Chatbot using Seq2Seq LSTM models\n",
    "In this notebook, we will assemble a seq2seq LSTM model using Keras Functional API to create a working Chatbot which would answer questions asked to it.\n",
    "\n",
    "Chatbots have become applications themselves. You can choose the field or stream and gather data regarding various questions. We can build a chatbot for an e-commerce webiste or a school website where parents could get information about the school.\n",
    "\n",
    "\n",
    "Messaging platforms like Allo have implemented chatbot services to questionsage users. The famous [Google Assistant](https://assistant.google.com/), [Siri](https://www.apple.com/in/siri/), [Cortana](https://www.microsoft.com/en-in/windows/cortana) and [Alexa](https://www.alexa.com/) may have been build using simialr models.\n",
    "\n",
    "So, let's start building our Chatbot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tm5g4WIG5ym2"
   },
   "source": [
    "## 1) Importing the packages\n",
    "\n",
    "We will import [TensorFlow](https://www.tensorflow.org) and our beloved [Keras](https://www.tensorflow.org/guide/keras). Also, we import other modules which help in defining model layers.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgZHR8TO0lFF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing, utils\n",
    "\n",
    "print( tf.VERSION )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxiGOLldKOQD"
   },
   "source": [
    "## 2) Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imkdw4os6FI4"
   },
   "source": [
    "### A) Download the data\n",
    "\n",
    "The dataset hails from [chatterbot/questionslish on Kaggle](https://www.kaggle.com/kausr25/chatterbotquestionslish).com by [kausr25](https://www.kaggle.com/kausr25). It contains pairs of questions and answers based on a number of subjects like food, history, AI etc.\n",
    "\n",
    "The raw data could be found from this repo -> https://github.com/shubham0204/Dataset_Archives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i6u8US30ufe"
   },
   "outputs": [],
   "source": [
    "\n",
    "#import requests, zipfile, io\n",
    "\n",
    "#r = requests.get( 'https://github.com/shubham0204/Dataset_Archives/blob/master/chatbot_nlp.zip?raw=true' ) \n",
    "#z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "#z.extractall()\n",
    "\n",
    "#from tensorflow.keras import preprocessing , utils\n",
    "#import os\n",
    "#import yaml\n",
    "#\n",
    "#dir_path = 'chatbot_nlp/data'\n",
    "#files_list = os.listdir(dir_path + os.sep)\n",
    "#\n",
    "#questions = list()\n",
    "#answers = list()\n",
    "#\n",
    "#for filepath in files_list:\n",
    "#    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "#    docs = yaml.safe_load(stream)\n",
    "#    conversations = docs['conversations']\n",
    "#    for con in conversations:\n",
    "#        if len( con ) > 2 :\n",
    "#            questions.append(con[0])\n",
    "#            replies = con[ 1 : ]\n",
    "#            ans = ''\n",
    "#            for rep in replies:\n",
    "#                ans += ' ' + rep\n",
    "#            answers.append( ans )\n",
    "#        elif len( con )> 1:\n",
    "#            questions.append(con[0])\n",
    "#            answers.append(con[1])\n",
    "#\n",
    "#answers_with_tags = list()\n",
    "#for i in range( len( answers ) ):\n",
    "#    if type( answers[i] ) == str:\n",
    "#        answers_with_tags.append( answers[i] )\n",
    "#    else:\n",
    "#        questions.pop( i )\n",
    "#\n",
    "#answers = list()\n",
    "#for i in range( len( answers_with_tags ) ) :\n",
    "#    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "#\n",
    "#tokenizer = preprocessing.text.Tokenizer()\n",
    "#tokenizer.fit_on_texts( questions + answers )\n",
    "#VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "#print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "#lines= pd.read_table('jpn.txt', names=['questions', 'answers'])\n",
    "#data_path = '../../Dataset/Bangladesh Dummy dataset from wikipedia.txt'\n",
    "data_path = '../../../Dataset/Dummy data from wikipedia short.txt'\n",
    "\n",
    "\n",
    "with open(data_path,'r', encoding='utf-8') as f:\n",
    "    lines = f.read()\n",
    "\n",
    "lines = \" \".join(lines.split())\n",
    "lines = re.sub(r\"\\s+\", \" \", lines)\n",
    "lines = lines.replace('\\n', ' ')\n",
    "\n",
    "sentences = sent_tokenize(lines)\n",
    "sent = np.asarray(sentences)\n",
    "sentTwo = sent[:-1].reshape(len(sent)//2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Bangladesh officially the People's Republic of Bangladesh (গণপ্রজাতন্ত্রী বাংলাদেশ Gônoprojatontri Bangladesh), is a country in South Asia.\",\n",
       "        \"While it is the 92nd-largest country, spanning 147,570 square kilometres (56,980 sq mi), it is the world's 8th-most populous country with a population nearing 163 million, making it one of the most densely populated countries in the world.\"],\n",
       "       ['Bangladesh shares land borders with India to the west, north and the east and Myanmar to the east, whereas the Bay of Bengal lies to its south.',\n",
       "        'Dhaka, its capital and largest city, is also the economic, political and the cultural hub of the country.'],\n",
       "       ['Chittagong, the largest sea port, is the second largest city.',\n",
       "        \"The country's geography is dominated by the Ganges delta which empties into the Bay of Bengal the combined waters of several river systems, including those of the Brahmaputra and the Ganges.\"],\n",
       "       ['As a result, the country is criss-crossed by numerous rivers and inland water ways.',\n",
       "        'Highlands with evergreen forests cover the landscape in the northeastern and southeastern regions of the country.'],\n",
       "       ['The country also features the longest natural sea beach and most of the largest mangrove forest in the world.',\n",
       "        \"The country's biodiversity includes a vast array of plants and wildlife, including the endangered Bengal tiger, the national animal.\"],\n",
       "       ['Bangladesh forms the largest and eastern part of the Bengal region.',\n",
       "        'According to the ancient Indian epics, Ramayana and Mahabharata, the Vanga Kingdom, one of the namesakes of the Bengal region, was known as an ally of the legendary Ayodhya and was notable for its strong navy.'],\n",
       "       ['In the ancient and classical period of the Indian subcontinent, the territory of Bangladesh was home to many principalities, including the Pundra, the Gangaridai, Gauda, Samatata and Harikela.',\n",
       "        'It was also a Mauryan province under the reign of Ashoka.'],\n",
       "       ['The principalities were notable for their overseas trade, their contacts with the Roman world, the export of fine muslin and silk to the Middle East, and spreading of philosophy and art to Southeast Asia.',\n",
       "        'The Pala Empire, the Chandra dynasty and the Sena dynasty were the last pre-Islamic Bengali middle kingdoms.'],\n",
       "       ['Islam was introduced during the Pala Empire, through trade with the Abbasid Caliphate, but following the early conquest of Bakhtiyar Khalji and the subsequent establishment of the Delhi Sultanate and preaching of Shah Jalal in East Bengal, it fully spread across the entire region.',\n",
       "        'Later, it was absorbed into the Mughal Empire in 1576, although part of the region was overrun by the Suri Empire.'],\n",
       "       ['Following the decline of the Mughal Empire in the early 1700s, Bengal became a semi-independent state under the Nawabs of Bengal, ultimately led by Siraj ud-Daulah.',\n",
       "        'It was later conquered by the British East India Company at the Battle of Plassey in 1757.'],\n",
       "       ['The borders of modern Bangladesh were established with the separation of Bengal and India in August 1947, when the region became East Pakistan as a part of the newly formed State of Pakistan following the Boundary of the Partition of India.',\n",
       "        'Later the rise of the Bengali nationalist and self-determination movement led to the Liberation War and eventually resulted in the emergence of Bangladesh as an independent sovereign in 1971.'],\n",
       "       ['Bengalis, who speak the official Bengali language, make up 98% of the population of Bangladesh.',\n",
       "        \"The politically dominant Bengali Muslims make the nation the world's fourth largest Muslim-majority country.\"],\n",
       "       [\"While recognising Islam as the country's established religion, the constitution grants freedom of religion to non-Muslims.\",\n",
       "        'A middle power, Bangladesh is a unitary parliamentary democracy and constitutional republic in the Westminster tradition.'],\n",
       "       ['The country is divided into eight administrative divisions and sixty-four districts.',\n",
       "        'It is one of the emerging and growth-leading economies of the world, and is listed among the Next Eleven countries.'],\n",
       "       ['It has one of the fastest real GDP growth rates in the world.',\n",
       "        'Its gross domestic product ranks 39th largest in the world in terms of market exchange rates and 29th in purchasing power parity.'],\n",
       "       ['Its per capita income ranks 143th and 136th in two measures.',\n",
       "        'While in the recent years Bangladesh has registered notable success in using Microcredit as a tool for poverty alleviation, women empowerment, generation of income through export of RMG, population control, reducing child mortality and combating natural disasters; the country continues to face the challenges of Rohingya refugee, terrorism, corruption, and erratic climate change.'],\n",
       "       ['The etymology of Bangladesh (Country of Bengal) can be traced to the early 20th century, when Bengali patriotic songs, such as Namo Namo Namo Bangladesh Momo by Kazi Nazrul Islam and Aaji Bangladesher Hridoy by Rabindranath Tagore, used the term.',\n",
       "        'The term Bangladesh was often written as two words, Bangla Desh, in the past.'],\n",
       "       ['Starting in the 1950s, Bengali nationalists used the term in political rallies in East Pakistan.',\n",
       "        'The exact origin of the word Bangla is unknown, though it is believed to come from \"Vanga\", an ancient kingdom and geopolitical division on the Ganges delta in the Indian subcontinent.'],\n",
       "       ['It was located in southern Bengal, with the core region including present-day southern West Bengal (India) and southwestern Bangladesh.',\n",
       "        'The suffix \"al\" came to be added to it from the fact that the ancient rajahs of this land raised mounds of earth 10 feet high and 20 in breadth in lowlands at the foot of the hills which were called \"al\".'],\n",
       "       ['From this suffix added to the Bung, the name Bengal arose and gained currency\".',\n",
       "        \"Support to this view is found in Ghulam Husain Salim's Riyaz-us-Salatin.\"],\n",
       "       ['Other theories point to a Bronze Age proto-Dravidian tribe, the Austric word \"Bonga\" (Sun god), and the Iron Age Vanga Kingdom.',\n",
       "        'The Indo-Aryan suffix Desh is derived from the Sanskrit word deśha, which means \"land\" or \"country\".'],\n",
       "       ['Hence, the name Bangladesh means \"Land of Bengal\" or \"Country of Bengal\".',\n",
       "        'The term Bangla denotes both the Bengal region and the Bengali language.'],\n",
       "       ['The earliest known usage of the term is the Nesari plate in 805 AD.',\n",
       "        'The term Vangaladesa is found in 11th-century South Indian records.'],\n",
       "       ['The term gained official status during the Sultanate of Bengal in the 14th century.',\n",
       "        'Shamsuddin Ilyas Shah proclaimed himself as the first \"Shah of Bangala\" in 1342.'],\n",
       "       ['The word Bangla became the most common name for the region during the Islamic period.',\n",
       "        'The Portuguese referred to the region as Bengala in the 16th century.'],\n",
       "       ['History Main articles: History of Bengal and History of Bangladesh Early and medieval periods The 9th-century ruins of Somapura Mahavihara.',\n",
       "        'The ruins hosted the largest monastery in pre-Islamic Bangladesh and is a UNESCO World Heritage Site The 15th-century Sixty Dome Mosque is the largest mosque in Bangladesh that was built during the period of the Bengal Sultanate The 17th-century incomplete Lalbagh Fort is the largest fort in Bangladesh from the period of the Mughal Empire, when the country formed part of Bengal Subah Stone Age tools found in Bangladesh indicate human habitation for over 20,000 years, and remnants of Copper Age settlements date back 4,000 years.'],\n",
       "       ['Ancient Bengal was settled by Austroasiatics, Tibeto-Burmans, Dravidians and Indo-Aryans in consecutive waves of migration.',\n",
       "        'Archaeological evidence confirms that by the second millennium BCE, rice-cultivating communities inhabited the region.'],\n",
       "       ['By the 11th century people lived in systemically-aligned housing, buried their dead, and manufactured copper ornaments and black and red pottery.',\n",
       "        'The Ganges, Brahmaputra and Meghna rivers were natural arteries for communication and transportation, and estuaries on the Bay of Bengal permitted maritime trade.'],\n",
       "       ['The early Iron Age saw the development of metal weaponry, coinage, agriculture and irrigation.',\n",
       "        'Major urban settlements formed during the late Iron Age, in the mid-first millennium BCE, when the Northern Black Polished Ware culture developed.'],\n",
       "       ['In 1879, Alexander Cunningham identified Mahasthangarh as the capital of the Pundra Kingdom mentioned in the Rigveda.',\n",
       "        'The oldest inscription in Bangladesh was found in Mahasthangarh and dates from the 3rd century BCE.'],\n",
       "       ['It is written in the Brahmi script.',\n",
       "        'Greek and Roman records of the ancient Gangaridai Kingdom, which (according to legend) deterred the invasion of Alexander the Great, are linked to the fort city in Wari-Bateshwar.'],\n",
       "       [\"The site is also identified with the prosperous trading center of Souanagoura listed on Ptolemy's world map.\",\n",
       "        'Roman geographers noted a large seaport in southeastern Bengal, corresponding to the present-day Chittagong region.'],\n",
       "       [\"Ancient Buddhist and Hindu states which ruled Bangladesh included the Vanga, Samatata and Pundra kingdoms, the Mauryan and Gupta Empires, the Varman dynasty, Shashanka's kingdom, the Khadga and Candra dynasties, the Pala Empire, the Sena dynasty, the Harikela kingdom and the Deva dynasty.\",\n",
       "        'These states had well-developed currencies, banking, shipping, architecture and art, and the ancient universities of Bikrampur and Mainamati hosted scholars and students from other parts of Asia.'],\n",
       "       ['Xuanzang of China was a noted scholar who resided at the Somapura Mahavihara (the largest monastery in ancient India), and Atisa travelled from Bengal to Tibet to preach Buddhism.',\n",
       "        'The earliest form of the Bengali language began to the emerge during the eighth century.'],\n",
       "       ['Early Muslim explorers and missionaries arrived in Bengal late in the first millennium CE.',\n",
       "        'The Islamic conquest of Bengal began with the 1204 invasion by Muhammad bin Bakhtiyar Khalji; after annexing Bengal to the Delhi Sultanate, Khilji waged a military campaign in Tibet.'],\n",
       "       ['Bengal was ruled by the Delhi Sultanate for a century by governors from the Mamluk, Balban and Tughluq dynasties.',\n",
       "        'Subsequently the independent Bengal Sultanate was established by the rabel governors in 1352.'],\n",
       "       ['During their rule Bengal was transformed into a cosmopolitan Islamic superpower and became a major trading nation in the world, often referred by the Europeans as the richest country to trade with.',\n",
       "        \"The sultanate's ruling houses included the Ilyas Shahi, Jalaluddin Muhammad Shah, Hussain Shahi, Suri and Karrani dynasties, and the era saw the introduction of a distinct mosque architecture and the tangka currency.\"],\n",
       "       ['The Arakan region was brought under Bengali hegemony.',\n",
       "        'The Bengal Sultanate was visited by explorers Ibn Battuta, Admiral Zheng He and Niccolo De Conti.'],\n",
       "       ['The Khorasanis referred to the land as an \"inferno full of gifts\", due to its unbearable climate but abundance of wealth.',\n",
       "        'During the late 16th century, the Baro-Bhuyan (a confederation of Muslim and Hindu aristocrats) ruled eastern Bengal; its leader was the Mansad-e-Ala, a title held by Isa Khan and his son Musa Khan.'],\n",
       "       ['The Khan dynasty are considered local heroes for resisting North Indian invasions with their river navies.',\n",
       "        'The Mughal Empire controlled Bengal by the 17th century.'],\n",
       "       ['During the reign of Emperor Akbar, the Bengali agrarian calendar was reformed to facilitate tax collection.',\n",
       "        'The Mughals established Dhaka as a fort city and commercial metropolis, and it was the capital of Mughal Bengal for 75 years.'],\n",
       "       ['In 1666, the Mughals expelled the Arakanese from Chittagong.',\n",
       "        'Mughal Bengal attracted foreign traders for its muslin and silk goods, and the Armenians were a notable merchant community.'],\n",
       "       ['A Portuguese settlement in Chittagong flourished in the southeast, and a Dutch settlement in Rajshahi existed in the north.',\n",
       "        'Bengal accounted for 40% of overall Dutch imports from Asia; including more than 50% of textiles and around 80% of silks.'],\n",
       "       [\"The Bengal Subah, described as the Paradise of the Nations, was the empire's wealthiest province, and a major global exporter, a notable center of worldwide industries such as muslin, cotton textiles, silk, and shipbuilding,.\",\n",
       "        \"Its citizens also enjoyed one of the world's most superior living standards.\"],\n",
       "       [\"Map of Bengal and Bihar, dated 1776 During the 18th century, the Nawabs of Bengal became the region's de facto rulers.\",\n",
       "        \"The title of the ruler is popularly known as the Nawab of Bengal, Bihar and Orissa, given that the Bengali Nawab's realm encompassed much of the eastern subcontinent.\"],\n",
       "       ['The Nawabs forged alliances with European colonial companies, which made the region relatively prosperous early in the century.',\n",
       "        'Bengal accounted for 50% of the gross domestic product of the empire.'],\n",
       "       ['The Bengali economy relied on textile manufacturing, shipbuilding, saltpetre production, craftsmanship and agricultural produce.',\n",
       "        'Bengal was a major hub for international trade - silk and cotton textiles from Bengal were worn in Europe, Japan, Indonesia and Central Asia.'],\n",
       "       ['Annual Bengali shipbuilding output was 223,250 tons, compared to an output of 23,061 tons in the nineteen colonies of North America.',\n",
       "        'Bengali shipbuilding proved to be more advanced than European shipbuilding prior to the Industrial Revolution.'],\n",
       "       ['The flush deck of Bengali rice ships was later replicated in European shipbuilding to replace the stepped deck design for ship hulls.',\n",
       "        'The Bengali Muslim population was a product of conversion and religious evolution, and their pre-Islamic beliefs included elements of Buddhism and Hinduism.'],\n",
       "       ['The construction of mosques, Islamic academies (madrasas) and Sufi monasteries (khanqahs) facilitated conversion, and Islamic cosmology played a significant role in developing Bengali Muslim society.',\n",
       "        'Scholars have theorised that Bengalis were attracted to Islam by its egalitarian social order, which contrasted with the Hindu caste system.'],\n",
       "       ['One of the notable Muslim preachers was Shah Jalal who arrived in the region of Sylhet in 1303 with many other disciples to preach the religion to the people.',\n",
       "        'By the 15th century, Muslim poets were writing in the Bengali language.'],\n",
       "       ['Notable medieval Bengali Muslim poets included Daulat Qazi, Abdul Hakim and Alaol.',\n",
       "        'Syncretic cults, such as the Baul movement, emerged on the fringes of Bengali Muslim society.'],\n",
       "       ['The Persianate culture was significant in Bengal, where cities like Sonargaon became the easternmost centers of Persian influence.',\n",
       "        \"The Mughals had aided France during the Seven Years' War to avoid loosing the Bengal region to the British.\"],\n",
       "       ['However, in the Battle of Plassey the British East India Company registered a decisive victory over the Nawab of Bengal and his French allies on 22 June 1757, under the leadership of Robert Clive.',\n",
       "        'The battle followed the order of Siraj-ud-Daulah, the last independent Nawab of Bengal, to the English to stop the extension of their fortification.'],\n",
       "       [\"Robert Clive bribed Mir Jafar, the commander-in-chief of the Nawab's army, and also promised him to make him Nawab of Bengal which helped him to defeat Siraj-ud-Daulah and capture Calcutta.\",\n",
       "        \"The battle consolidated the Company's presence in Bengal, which later expanded to cover much of India over the next hundred years.\"],\n",
       "       ['Although they had lost control of Bengal Subah, Shah Alam II was involved in the Bengal War which ended once more in their defeat at the Battle of Buxar.',\n",
       "        'Colonial period Main articles: Bengal Presidency and Eastern Bengal and Assam Panam Road, Narayanganj during British rule in 1875 After the 1757 Battle of Plassey, Bengal was the first region of the Indian subcontinent conquered by the British East India Company.'],\n",
       "       ['The company formed the Presidency of Fort William, which administered the region until 1858.',\n",
       "        'A notable aspect of company rule was the Permanent Settlement, which established the feudal zamindari system.'],\n",
       "       [\"The plunder of Bengal directly contributed to the Industrial Revolution in Britain, with the capital amassed from Bengal used to invest in British industries such as textile and greatly increase British wealth, while at the same time leading to deindustrialisation of Bengal's traditional textile industry.\",\n",
       "        'The economic mismanagement directly led to the Great Bengal famine of 1770, which is estimated to have caused the deaths of about 10 million people, as a third of the population in the affected region starved to death.'],\n",
       "       ['Several rebellions broke out during the early 19th century (including one led by Titumir), but British rule displaced the Muslim ruling class.',\n",
       "        'A conservative Islamic cleric, Haji Shariatullah, sought to overthrow the British by propagating Islamic revivalism.']],\n",
       "      dtype='<U533')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bangladesh officially the peoples republic of ...</td>\n",
       "      <td>&lt;START&gt; bangladesh shares land borders with in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bangladesh shares land borders with india to t...</td>\n",
       "      <td>&lt;START&gt; chittagong the largest sea port is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chittagong the largest sea port is the second ...</td>\n",
       "      <td>&lt;START&gt; as a result the country is crisscrosse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>as a result the country is crisscrossed by num...</td>\n",
       "      <td>&lt;START&gt; the country also features the longest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the country also features the longest natural ...</td>\n",
       "      <td>&lt;START&gt; bangladesh forms the largest and easte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bangladesh forms the largest and eastern part ...</td>\n",
       "      <td>&lt;START&gt; in the ancient and classical period of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>in the ancient and classical period of the ind...</td>\n",
       "      <td>&lt;START&gt; the principalities were notable for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>the principalities were notable for their over...</td>\n",
       "      <td>&lt;START&gt; islam was introduced during the pala e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>islam was introduced during the pala empire th...</td>\n",
       "      <td>&lt;START&gt; following the decline of the mughal em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>following the decline of the mughal empire in ...</td>\n",
       "      <td>&lt;START&gt; the borders of modern bangladesh were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  bangladesh officially the peoples republic of ...   \n",
       "1  bangladesh shares land borders with india to t...   \n",
       "2  chittagong the largest sea port is the second ...   \n",
       "3  as a result the country is crisscrossed by num...   \n",
       "4  the country also features the longest natural ...   \n",
       "5  bangladesh forms the largest and eastern part ...   \n",
       "6  in the ancient and classical period of the ind...   \n",
       "7  the principalities were notable for their over...   \n",
       "8  islam was introduced during the pala empire th...   \n",
       "9  following the decline of the mughal empire in ...   \n",
       "\n",
       "                                             answers  \n",
       "0  <START> bangladesh shares land borders with in...  \n",
       "1  <START> chittagong the largest sea port is the...  \n",
       "2  <START> as a result the country is crisscrosse...  \n",
       "3  <START> the country also features the longest ...  \n",
       "4  <START> bangladesh forms the largest and easte...  \n",
       "5  <START> in the ancient and classical period of...  \n",
       "6  <START> the principalities were notable for th...  \n",
       "7  <START> islam was introduced during the pala e...  \n",
       "8  <START> following the decline of the mughal em...  \n",
       "9  <START> the borders of modern bangladesh were ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1, col2 = create_dataset(sentTwo)\n",
    "#col1 = col1.reshape(-1)\n",
    "col2 = col2.reshape(-1,1)\n",
    "#col2.shape\n",
    "dt = np.concatenate((col1,col2), axis=1)\n",
    "\n",
    "lines = pd.DataFrame(dt, columns=['questions','answers'])\n",
    "# Lowercase all characters\n",
    "lines.questions=lines.questions.apply(lambda x: x.lower())\n",
    "lines.answers=lines.answers.apply(lambda x: x.lower())\n",
    "\n",
    "# to install mecab\n",
    "# sudo apt install mecab mecab-ipadic-utf8\n",
    "#import MeCab\n",
    "#wakati = MeCab.Tagger(\"-Owakati\")\n",
    "#lines.answers = lines.answers.apply(lambda x: wakati.parse(x).strip(\"\\n\"))\n",
    "\n",
    "# Remove quotes\n",
    "lines.questions=lines.questions.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.answers=lines.answers.apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "# Remove all the special characters\n",
    "lines.questions=lines.questions.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.answers=lines.answers.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "#remove_digits = str.maketrans('', '', digits)\n",
    "#lines.questions=lines.questions.apply(lambda x: x.translate(remove_digits))\n",
    "#lines.answers = lines.answers.apply(lambda x: re.sub(\"[123456789]\", \"\", x))\n",
    "# Remove extra spaces\n",
    "\n",
    "lines.questions=lines.questions.apply(lambda x: x.strip())\n",
    "lines.answers=lines.answers.apply(lambda x: x.strip())\n",
    "lines.questions=lines.questions.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.answers=lines.answers.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "lines.answers = lines.answers.apply(lambda x : '<START> ' + x + ' <END>')\n",
    "lines.head(10)\n",
    "#lines.answers.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 562\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( lines.questions + lines.answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "index2word = {}\n",
    "for k, v in word_index.items():\n",
    "    if v < 15000:\n",
    "        index2word[v] = k\n",
    "    if v > 15000:\n",
    "        continue\n",
    "\n",
    "word2index = {}\n",
    "for k, v in index2word.items():\n",
    "    word2index[v] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nF1mDKD_R6Os"
   },
   "source": [
    "### B) Reading the data from the files\n",
    "\n",
    "We parse each of the `.yaml` files.\n",
    "\n",
    "*   Concatenate two or more sentences if the answer has two or more of them.\n",
    "*   Remove unwanted data types which are produced while parsing the data.\n",
    "*   Append `<START>` and `<END>` to all the `answers`.\n",
    "*   Create a `Tokenizer` and load the whole vocabulary ( `questions` + `answers` ) into it.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzsaO1YvS-M8"
   },
   "source": [
    "\n",
    "### C) Preparing data for Seq2Seq model\n",
    "\n",
    "Our model requires three arrays namely `encoder_input_data`, `decoder_input_data` and `decoder_output_data`.\n",
    "\n",
    "For `encoder_input_data` :\n",
    "* Tokenize the `questions`. Pad them to their maximum lquestionsth.\n",
    "\n",
    "For `decoder_input_data` :\n",
    "* Tokenize the `answers`. Pad them to their maximum lquestionsth.\n",
    "\n",
    "For `decoder_output_data` :\n",
    "\n",
    "* Tokenize the `answers`. Remove the first element from all the `tokenized_answers`. This is the `<START>` element which we added earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5AD9ooQKc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 44) 44\n",
      "(57, 47) 47\n",
      "(57, 47, 562)\n"
     ]
    }
   ],
   "source": [
    "questions = lines.questions \n",
    "answers = lines.answers\n",
    "\n",
    "# encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print( encoder_input_data.shape , maxlen_questions )\n",
    "\n",
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max([ len(x) for x in tokenized_answers ])\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )\n",
    "\n",
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )\n",
    "\n",
    "# Saving all the arrays to storage\n",
    "#np.save( 'Saved Arrays/enc_in_data.npy' , encoder_input_data )\n",
    "#np.save( 'Saved Arrays/dec_in_data.npy' , decoder_input_data )\n",
    "#np.save( 'Saved Arrays/dec_tar_data.npy' , decoder_output_data )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SwY3T139l19"
   },
   "source": [
    "## 3) Defining the Encoder-Decoder model\n",
    "The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
    "\n",
    "\n",
    "*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n",
    "*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n",
    "*   LSTM layer : Provide access to Long-Short Term cells.\n",
    "\n",
    "Working : \n",
    "\n",
    "1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n",
    "2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n",
    "3.   These states are set in the LSTM cell of the decoder.\n",
    "4.   The decoder_input_data comes in through the Embedding layer.\n",
    "5.   The Embeddings goes in LSTM cell ( which had the states ) to produce seqeunces.\n",
    "\n",
    "**Important points :**\n",
    "\n",
    "\n",
    "*   `50` is the output of the GloVe embeddings.\n",
    "*   `embedding_matrix` is the GloVe embedding which we downloaded earlier.\n",
    "\n",
    "\n",
    "<center><img style=\"float: center;\" src=\"https://cdn-images-1.medium.com/max/1600/1*bnRvZDDapHF8Gk8soACtCQ.gif\"></center>\n",
    "\n",
    "\n",
    "Image credits to [Hackernoon](https://hackernoon.com/tutorial-3-what-is-seq2seq-for-text-summarization-and-why-68ebaa644db0).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "home = str(Path.home())\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(home + '/GlovePretrainedVectors/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        #print(word)\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        #print(coefs)\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "print(\"Glove Loaded\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = embedding_matrix_creater(50, word_index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from keras.layers import Embedding\n",
    "\n",
    "embed_layer = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=50, trainable=True,)\n",
    "embed_layer.build((None,))\n",
    "embed_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gUYtOwv21rt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     28100       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding[1][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 562)    28662       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 97,162\n",
      "Trainable params: 97,162\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "#encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 50 , mask_zero=True ) (encoder_inputs)\n",
    "\n",
    "encoder_embedding = embed_layer(encoder_inputs)\n",
    "\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 50 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "#decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 50 , mask_zero=True) (decoder_inputs)\n",
    "\n",
    "decoder_embedding = embed_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = tf.keras.layers.LSTM( 50 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9g_8sR7WWf3"
   },
   "source": [
    "## 4) Training the model\n",
    "We train the model for a number of epochs with `RMSprop` optimizer and `categorical_crossentropy` loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N74NZnfo3Id-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 1s 23ms/sample - loss: 6.2014\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 5.4281\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 4.7704\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 4.2125\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 3.7244\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 3.4047\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 3.2173\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 3.0913\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 2.9980\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 2.9226\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.8578\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 2.8028\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 2.7613\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.7167\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.6698\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.6370\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.6046\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.5814\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.5573\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.5338\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.5120\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.5054\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4788\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4642\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4474\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4317\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4193\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.4084\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3889\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3765\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3709\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3520\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3382\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 2.3312\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3159\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.3024\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2932\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2788\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2663\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2535\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2443\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2314\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2155\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2075\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.2002\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1785\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1678\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1594\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1449\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1322\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1163\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.1072\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 0s 6ms/sample - loss: 2.0952\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0807\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0665\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0560\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0394\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0253\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 2.0149\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9991\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9847\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 0s 6ms/sample - loss: 1.9703\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9632\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9463\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9307\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 0s 6ms/sample - loss: 1.9213\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.9006\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8954\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8778\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8608\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8453\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8383\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8239\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.8070\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.7982\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.7802\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.7645\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.7551\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.7432\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.7237\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.7130\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.7043\n",
      "Epoch 83/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.6831\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.6717\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.6547\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.6531\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.6333\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.6183\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.6066\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5928\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.5805\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5689\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5603\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.5370\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5262\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5175\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.5007\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 0s 8ms/sample - loss: 1.4914\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.4764\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 0s 7ms/sample - loss: 1.4599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=10, epochs=100 ) \n",
    "model.save( 'model.h5' ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sOLQr0M-lAe"
   },
   "source": [
    "## 5) Defining inference models\n",
    "We create inference models which help in predicting answers.\n",
    "\n",
    "**Encoder inference model** : Takes the question as input and outputs LSTM states ( `h` and `c` ).\n",
    "\n",
    "**Decoder inference model** : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the answer input seqeunces ( ones not having the `<start>` tag ). It will output the answers for the question which we fed to the encoder model and its state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1u5DE4qo3Mf2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 50 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 50 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxZp0ZRy-6dA"
   },
   "source": [
    "## 6) Talking with our Chatbot\n",
    "\n",
    "First, we define a method `str_to_tokens` which converts `str` questions to Integer tokens with padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5P_wDD554q9O"
   },
   "outputs": [],
   "source": [
    "\n",
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    #return tokens_list\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens(\"Bangladesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djEPrfJBmZE-"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.   First, we take a question as input and predict the state values using `enc_model`.\n",
    "2.   We set the state values in the decoder's LSTM.\n",
    "3.   Then, we generate a sequence which contains the `<start>` element.\n",
    "4.   We input this sequence in the `dec_model`.\n",
    "5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n",
    "6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum answer lquestionsth.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zBmN8qB3O-e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : Bangladesh\n",
      " the the is is of the largest sea and rivers and the world end\n",
      "Enter question : Muslim\n",
      " the the is is of the largest sea and rivers and and inland end\n",
      "Enter question : islam\n",
      " the the is is of the largest sea and rivers and and inland end\n",
      "Enter question : cat\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a3576c66748e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Enter question : '\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-a6ee396da3f7>\u001b[0m in \u001b[0;36mstr_to_tokens\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#return tokens_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtokens_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen_questions\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cat'"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ChatBot_using_seq2seq.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
